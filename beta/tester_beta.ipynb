{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4291964d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyautogui\n",
    "import time\n",
    "\n",
    "time.sleep(2.0)\n",
    "pyautogui.rightClick()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fb6eeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CONFIG ==============================================================\n",
    "from pathlib import Path\n",
    "import tempfile\n",
    "# Encoder & quality controls\n",
    "ENCODER      = \"libx264\"   # \"libx264\" (best quality) or \"videotoolbox\" (fast on Mac)\n",
    "CRF          = 16          # 16–18 = visually lossless; bigger = smaller files\n",
    "X264_PRESET  = \"slow\"      # \"slow\" (quality), \"medium\", \"fast\"\n",
    "PROFILE      = \"high\"      # h264 profile\n",
    "LEVEL        = \"4.2\"       # OK for 1080p30/60; adjust if needed\n",
    "COPY_AUDIO   = True        # keep original audio\n",
    "\n",
    "\n",
    "# Where to save the rendered video:\n",
    "OUTPUT_DIR = Path.home() / \"Downloads\" / \"reddit1_captioned\"   # <— change me\n",
    "\n",
    "# Filename pattern (placeholders: {stem}=input filename stem, {ts}=timestamp, {anim}=ANIM)\n",
    "FILENAME_TEMPLATE = \"exported_{ts}.mp4\"\n",
    "\n",
    "\n",
    "#INPUT_VIDEO       = Path.home() / \"Downloads\" / \"reddit1_filmora_clipstore\" / \"tester88888.mp4\"\n",
    "MODEL_NAME        = \"small.en\"       # tiny/base/small/medium/large-v3; *.en faster for English\n",
    "\n",
    "# Caption look\n",
    "FONT_SIZE         = 210\n",
    "UPPERCASE         = True\n",
    "\n",
    "# Outline controls\n",
    "BORDER_PX         = 12.0             # base outline thickness (px)\n",
    "SHADOW_PX         = 2.0              # shadow strength\n",
    "BLUR_PX           = 0.0              # small blur reduces shimmer; try 0.3–0.8 if edges flicker\n",
    "STABILIZE_OUTLINE = True             # <<< turn this on to animate \\bord with scale\n",
    "\n",
    "# Timing hyperparams\n",
    "MIN_CAPTION_SEC   = 0.30\n",
    "CUT_AHEAD_SEC     = 0.00\n",
    "TAIL_HOLD_SEC     = 1.20\n",
    "\n",
    "# Grouping hyperparams (control words/characters per caption)\n",
    "MAX_WORDS_PER_CAP = 1\n",
    "MAX_CHARS_PER_CAP = None\n",
    "MAX_GAP_SEC       = 1.20\n",
    "\n",
    "# Animation\n",
    "# ANIM choices: \"none\",\"fade\",\"pop\",\"zoom\",\"bounce\",\"slide_up\",\"slide_down\",\n",
    "#               \"slide_left\",\"slide_right\",\"rotate\",\"inflate\",\"inflate_soft\"\n",
    "ANIM              = \"inflate\"\n",
    "ANIM_IN_MS        = 20000   # your original long ramp; try 200–400 for subtle pop\n",
    "ANIM_OUT_MS       = 50\n",
    "\n",
    "# Fonts\n",
    "CUSTOM_FONT_DIR   = Path.home() / \"Documents\" / \"mrbeast_caps\" / \"fonts\"\n",
    "\n",
    "# Rendering safety\n",
    "AUTO_PLAYRES      = True             # match ASS PlayRes to actual video resolution\n",
    "YUV444_RENDER     = True             # render subs in 4:4:4 to stabilize edges, then downsample\n",
    "# ========================================================================\n",
    "\n",
    "def probe_color_metadata(video_path: Path):\n",
    "    \"\"\"\n",
    "    Return dict with color_primaries, color_trc, colorspace, color_range (tv/pc) if present.\n",
    "    Prevents gamma/contrast shifts after burn-in.\n",
    "    \"\"\"\n",
    "    import json, subprocess\n",
    "    cmd = [\n",
    "        \"ffprobe\",\"-v\",\"error\",\"-select_streams\",\"v:0\",\n",
    "        \"-show_entries\",\"stream=color_primaries,color_transfer,color_space,color_range\",\n",
    "        \"-of\",\"json\", str(video_path)\n",
    "    ]\n",
    "    try:\n",
    "        data = json.loads(subprocess.check_output(cmd, text=True))\n",
    "        st = (data.get(\"streams\") or [{}])[0]\n",
    "        prim = st.get(\"color_primaries\")\n",
    "        trc  = st.get(\"color_transfer\")\n",
    "        spc  = st.get(\"color_space\")\n",
    "        rng  = st.get(\"color_range\")  # \"tv\" or \"pc\"\n",
    "        # Map ffprobe keys to ffmpeg options\n",
    "        out = {}\n",
    "        if prim: out[\"-color_primaries\"] = prim\n",
    "        if trc:  out[\"-color_trc\"]       = trc\n",
    "        if spc:  out[\"-colorspace\"]      = spc\n",
    "        if rng:  out[\"-color_range\"]     = rng\n",
    "        return out\n",
    "    except Exception:\n",
    "        return {}\n",
    "\n",
    "def build_encoder_flags():\n",
    "    \"\"\"\n",
    "    Choose encoder args for best visual fidelity.\n",
    "    \"\"\"\n",
    "    flags = []\n",
    "    if ENCODER == \"libx264\":\n",
    "        flags += [\"-c:v\",\"libx264\",\n",
    "                  \"-preset\", X264_PRESET,\n",
    "                  \"-profile:v\", PROFILE,\n",
    "                  \"-level:v\", LEVEL,\n",
    "                  \"-pix_fmt\",\"yuv420p\",\n",
    "                  \"-crf\", str(CRF)]\n",
    "        # Reasonable x264 params for detail retention without going crazy:\n",
    "        flags += [\"-x264-params\", \"aq-mode=2:aq-strength=1.0:ref=5:bframes=5:me=umh:subme=7\"]\n",
    "    else:  # \"videotoolbox\" (fast; OK quality if CRF ~18)\n",
    "        flags += [\"-c:v\",\"h264_videotoolbox\",\n",
    "                  \"-profile:v\", PROFILE,\n",
    "                  \"-pix_fmt\",\"yuv420p\",\n",
    "                  \"-crf\", str(CRF),\n",
    "                  \"-allow_sw\",\"1\"]\n",
    "    return flags\n",
    "\n",
    "\n",
    "\n",
    "import os, subprocess, shutil, platform, re, sys\n",
    "from datetime import timedelta\n",
    "from faster_whisper import WhisperModel\n",
    "import re\n",
    "from datetime import datetime \n",
    "\n",
    "def timestamp(fmt: str = \"%Y%m%d_%H%M%S\") -> str:\n",
    "    \"\"\"Current local time formatted for filenames.\"\"\"\n",
    "    return datetime.now().strftime(fmt)\n",
    "\n",
    "def sanitize_stem(stem: str) -> str:\n",
    "    \"\"\"Make a filesystem-safe stem.\"\"\"\n",
    "    return re.sub(r'[^A-Za-z0-9_.-]+', '_', stem).strip('_')\n",
    "\n",
    "def ensure_dir(p: Path) -> Path:\n",
    "    \"\"\"Create directory if needed and return it.\"\"\"\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "    return p\n",
    "\n",
    "\n",
    "# ---------- probe video resolution ----------\n",
    "def probe_resolution(video_path: Path) -> tuple[int, int]:\n",
    "    cmd = [\n",
    "        \"ffprobe\",\"-v\",\"error\",\"-select_streams\",\"v:0\",\n",
    "        \"-show_entries\",\"stream=width,height\",\"-of\",\"csv=s=x:p=0\", str(video_path)\n",
    "    ]\n",
    "    try:\n",
    "        out = subprocess.check_output(cmd, text=True).strip()\n",
    "        w, h = map(int, out.split(\"x\"))\n",
    "        return w, h\n",
    "    except Exception:\n",
    "        # fallback\n",
    "        return 1920, 1080\n",
    "\n",
    "# centers derived later once we know resolution\n",
    "CENTER_X, CENTER_Y = None, None\n",
    "\n",
    "# ---------- load Whisper with a supported compute_type ----------\n",
    "import platform as _pf\n",
    "def load_whisper_auto(model_name: str):\n",
    "    osname = _pf.system()\n",
    "    candidates = ([\"float16\", \"int8\", \"float32\"] if osname == \"Darwin\"\n",
    "                  else [\"int8_float16\", \"int8\", \"float16\", \"float32\"])\n",
    "    last = None\n",
    "    for ct in candidates:\n",
    "        try:\n",
    "            print(f\"[info] trying compute_type={ct} …\")\n",
    "            return WhisperModel(model_name, compute_type=ct, device=\"auto\")\n",
    "        except ValueError as e:\n",
    "            print(f\"[skip] {e}\")\n",
    "            last = e\n",
    "    raise last\n",
    "\n",
    "# ---------- font: use any .ttf/.otf in CUSTOM_FONT_DIR ----------\n",
    "def pick_custom_font(font_dir: Path):\n",
    "    font_dir.mkdir(parents=True, exist_ok=True)\n",
    "    candidates = list(font_dir.glob(\"*.ttf\")) + list(font_dir.glob(\"*.otf\"))\n",
    "    if not candidates:\n",
    "        print(\"\\n[FONT SETUP REQUIRED]\")\n",
    "        print(\"1) Download any .ttf or .otf font.\")\n",
    "        print(f\"2) Place it here: {font_dir}\")\n",
    "        print(\"3) Re-run.\")\n",
    "        raise SystemExit(\"[exit] No font found yet.\")\n",
    "    font_file = candidates[0]\n",
    "    family = None\n",
    "    try:\n",
    "        from fontTools.ttLib import TTFont  # optional (pip install fonttools)\n",
    "        tt = TTFont(font_file)\n",
    "        names = {n.nameID: n.toUnicode() for n in tt[\"name\"].names if n.toUnicode()}\n",
    "        family = names.get(1) or names.get(4)\n",
    "    except Exception:\n",
    "        family = font_file.stem\n",
    "    print(\"[font] Using file:\", font_file)\n",
    "    print(\"[font] Font family set to:\", family)\n",
    "    return font_file, family\n",
    "\n",
    "# ---------- ASS header template (filled later with resolution) ----------\n",
    "ASS_HEADER_TMPL = \"\"\"[Script Info]\n",
    "ScriptType: v4.00+\n",
    "PlayResX: {play_w}\n",
    "PlayResY: {play_h}\n",
    "ScaledBorderAndShadow: yes\n",
    "WrapStyle: 2\n",
    "\n",
    "[V4+ Styles]\n",
    "Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding\n",
    "; White text (Primary), THICK black outline, subtle shadow for separation.\n",
    "Style: Beast,{font},{size},&H00FFFFFF,&H00FFFFFF,&H00000000,&H64000000,-1,0,0,0,100,100,0,0,1,{border},{shadow},5,60,60,60,1\n",
    "\n",
    "[Events]\n",
    "Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text\n",
    "\"\"\"\n",
    "\n",
    "def _fmt_time(t: float) -> str:\n",
    "    td = timedelta(seconds=max(0.0, t))\n",
    "    cs = int(round(td.total_seconds() * 100))\n",
    "    h, rem = divmod(cs, 360000)\n",
    "    m, rem = divmod(rem, 6000)\n",
    "    s, cs = divmod(rem, 100)\n",
    "    return f\"{h}:{m:02d}:{s:02d}.{cs:02d}\"\n",
    "\n",
    "# compute start/end scales & animated \\bord when stabilizing\n",
    "def _scale_spec_for_anim(name: str):\n",
    "    name = (name or \"none\").lower()\n",
    "    # start_scale, end_scale\n",
    "    if name in (\"inflate\", \"inflate_soft\", \"pop\"):\n",
    "        return 80, 100\n",
    "    if name == \"zoom\":\n",
    "        return 60, 100\n",
    "    # slide/rotate/fade/none: no scale change\n",
    "    return 100, 100\n",
    "\n",
    "def _fmt_float(x: float) -> str:\n",
    "    # compact float formatting for ASS tags\n",
    "    return f\"{x:.2f}\".rstrip(\"0\").rstrip(\".\")\n",
    "\n",
    "def anim_tag(cx: int, cy: int, name: str, in_ms: int, out_ms: int,\n",
    "             border_px: float, stabilize_outline: bool, blur_px: float) -> str:\n",
    "    # snap to pixel to reduce subpixel shimmer\n",
    "    cx, cy = int(round(cx)), int(round(cy))\n",
    "    s0, s1 = _scale_spec_for_anim(name)\n",
    "    # outline start/end if stabilizing (inverse proportional to scale)\n",
    "    if stabilize_outline and (s0 != s1):\n",
    "        bord0 = border_px * (s0 / 100.0)\n",
    "        bord1 = border_px * (s1 / 100.0)\n",
    "        bord_tag0 = rf\"\\bord{_fmt_float(bord0)}\"\n",
    "        bord_anim = rf\"\\t(0,{in_ms},\\bord{_fmt_float(bord1)})\"\n",
    "    else:\n",
    "        bord0 = border_px\n",
    "        bord_tag0 = rf\"\\bord{_fmt_float(bord0)}\"\n",
    "        bord_anim = \"\"\n",
    "\n",
    "    blur_tag = (rf\"\\blur{_fmt_float(blur_px)}\" if blur_px and blur_px > 0 else \"\")\n",
    "\n",
    "    name = (name or \"none\").lower()\n",
    "    if name == \"none\":\n",
    "        return rf\"{{\\an5\\pos({cx},{cy}){bord_tag0}{blur_tag}}}\"\n",
    "    if name == \"fade\":\n",
    "        return rf\"{{\\an5\\pos({cx},{cy}){bord_tag0}{blur_tag}\\fad({in_ms},{out_ms})}}\"\n",
    "    if name == \"pop\":\n",
    "        return rf\"{{\\an5\\pos({cx},{cy}){bord_tag0}{blur_tag}\\fscx80\\fscy80\\t(0,{in_ms},\\fscx100\\fscy100){bord_anim}}}\"\n",
    "    if name == \"zoom\":\n",
    "        return rf\"{{\\an5\\pos({cx},{cy}){bord_tag0}{blur_tag}\\fscx60\\fscy60\\t(0,{in_ms},\\fscx100\\fscy100){bord_anim}}}\"\n",
    "    if name == \"bounce\":\n",
    "        return (rf\"{{\\an5\\move({cx},{cy-40},{cx},{cy},0,{in_ms}){bord_tag0}{blur_tag}\"\n",
    "                rf\"\\fscx120\\fscy120\\t(0,120,\\fscx95\\fscy95)\\t(120,{in_ms},\\fscx100\\fscy100){bord_anim}}}\")\n",
    "    if name == \"slide_up\":\n",
    "        return rf\"{{\\an5\\move({cx},{cy+60},{cx},{cy},0,{in_ms}){bord_tag0}{blur_tag}}}\"\n",
    "    if name == \"slide_down\":\n",
    "        return rf\"{{\\an5\\move({cx},{cy-60},{cx},{cy},0,{in_ms}){bord_tag0}{blur_tag}}}\"\n",
    "    if name == \"slide_left\":\n",
    "        return rf\"{{\\an5\\move({cx-140},{cy},{cx},{cy},0,{in_ms}){bord_tag0}{blur_tag}}}\"\n",
    "    if name == \"slide_right\":\n",
    "        return rf\"{{\\an5\\move({cx+140},{cy},{cx},{cy},0,{in_ms}){bord_tag0}{blur_tag}}}\"\n",
    "    if name == \"rotate\":\n",
    "        return rf\"{{\\an5\\pos({cx},{cy}){bord_tag0}{blur_tag}\\frz-12\\t(0,{in_ms},\\frz0)}}\"\n",
    "    if name == \"inflate\":\n",
    "        return rf\"{{\\an5\\pos({cx},{cy}){bord_tag0}{blur_tag}\\fscx80\\fscy80\\t(0,{in_ms},\\fscx100\\fscy100){bord_anim}}}\"\n",
    "    if name == \"inflate_soft\":\n",
    "        return (rf\"{{\\an5\\pos({cx},{cy}){bord_tag0}{blur_tag}\\fscx80\\fscy80\\alpha&H20&\\blur2\"\n",
    "                rf\"\\t(0,{in_ms},\\fscx100\\fscy100\\alpha&H00&\\blur0){bord_anim}}}\")\n",
    "    return rf\"{{\\an5\\pos({cx},{cy}){bord_tag0}{blur_tag}}}\"\n",
    "\n",
    "# ---------- Group words into captions ----------\n",
    "def clean_token(s: str) -> str:\n",
    "    s = (s or \"\").strip()\n",
    "    s = re.sub(r\"^\\s+|\\s+$\", \"\", s)\n",
    "    return re.sub(r\"^\\W+|\\W+$\", \"\", s)\n",
    "\n",
    "def group_words_to_captions(words,\n",
    "                            max_words=1,\n",
    "                            max_chars=None,\n",
    "                            max_gap_s=0.6):\n",
    "    lines, cur = [], []\n",
    "    last_end = None\n",
    "    for w in words:\n",
    "        token = clean_token(w[\"text\"])\n",
    "        if not token:\n",
    "            continue\n",
    "        gap = (w[\"start\"] - last_end) if last_end is not None else 0.0\n",
    "\n",
    "        join_len = len((\" \".join([x[\"text\"] for x in cur] + [token])).strip())\n",
    "        need_new = False\n",
    "        if last_end is not None and gap > max_gap_s:\n",
    "            need_new = True\n",
    "        if cur and len(cur) >= max_words:\n",
    "            need_new = True\n",
    "        if (not need_new) and (max_chars is not None) and (join_len > max_chars):\n",
    "            need_new = True\n",
    "\n",
    "        if need_new and cur:\n",
    "            lines.append(cur)\n",
    "            cur = []\n",
    "\n",
    "        cur.append({\"start\": float(w[\"start\"]), \"end\": float(w[\"end\"]), \"text\": token})\n",
    "        last_end = float(w[\"end\"])\n",
    "\n",
    "    if cur:\n",
    "        lines.append(cur)\n",
    "    return lines\n",
    "\n",
    "def build_center_caption_events(lines,\n",
    "                                play_w: int, play_h: int,\n",
    "                                uppercase=True,\n",
    "                                min_caption=0.30,\n",
    "                                cut_ahead=0.00,\n",
    "                                tail_hold=1.20,\n",
    "                                anim=\"none\",\n",
    "                                in_ms=220,\n",
    "                                out_ms=100,\n",
    "                                border_px=12.0,\n",
    "                                stabilize_outline=True,\n",
    "                                blur_px=0.0):\n",
    "    cx = int(round(play_w / 2))\n",
    "    cy = int(round(play_h / 2))\n",
    "    events = []\n",
    "    n = len(lines)\n",
    "    for i, ln in enumerate(lines):\n",
    "        t0 = float(ln[0][\"start\"])\n",
    "        natural_end = float(ln[-1][\"end\"])\n",
    "        t1 = max(natural_end, t0 + min_caption)\n",
    "\n",
    "        if i + 1 < n:\n",
    "            next_start = float(lines[i+1][0][\"start\"])\n",
    "            gap_after = max(0.0, next_start - natural_end - cut_ahead)\n",
    "            t1 = min(max(t1, natural_end + min(tail_hold, gap_after)), next_start - cut_ahead)\n",
    "        else:\n",
    "            t1 = max(natural_end + tail_hold, t0 + min_caption)\n",
    "\n",
    "        if t1 <= t0:\n",
    "            t1 = t0 + 0.05\n",
    "\n",
    "        text = \" \".join([w[\"text\"] for w in ln]).strip()\n",
    "        if uppercase:\n",
    "            text = text.upper()\n",
    "\n",
    "        ov = anim_tag(cx, cy, anim, in_ms, out_ms, border_px, stabilize_outline, blur_px)\n",
    "        events.append(f\"Dialogue: 0,{_fmt_time(t0)},{_fmt_time(t1)},Beast,,0,0,0,,{ov}{text}\")\n",
    "    return events\n",
    "import subprocess, shutil, platform, tempfile, inspect\n",
    "\n",
    "\n",
    "import subprocess, shutil, platform, tempfile, inspect\n",
    "\n",
    "def beta_captions_v3(INPUT_VIDEO) -> str:\n",
    "    print(f\"[debug] using {inspect.currentframe().f_code.co_name}\")\n",
    "\n",
    "    video_path = Path(INPUT_VIDEO).expanduser().resolve()\n",
    "    assert video_path.exists(), f\"Video not found: {video_path}\"\n",
    "    print(\"[info] video:\", video_path)\n",
    "\n",
    "    # Resolution & center\n",
    "    PLAY_W, PLAY_H = probe_resolution(video_path) if AUTO_PLAYRES else (1920, 1080)\n",
    "    cx, cy = (PLAY_W // 2, PLAY_H // 2) if (CENTER_X is None or CENTER_Y is None) else (CENTER_X, CENTER_Y)\n",
    "    print(f\"[info] PlayRes set to: {PLAY_W}x{PLAY_H} | Center=({cx},{cy})\")\n",
    "\n",
    "    # Transcribe\n",
    "    print(\"[info] loading Whisper model …\")\n",
    "    model = load_whisper_auto(MODEL_NAME)\n",
    "    print(\"[info] transcribing (word timestamps) …\")\n",
    "    segments, _ = model.transcribe(str(video_path), vad_filter=True, word_timestamps=True)\n",
    "\n",
    "    words = []\n",
    "    for seg in segments:\n",
    "        if seg.words:\n",
    "            for w in seg.words:\n",
    "                tok = (w.word or \"\").strip()\n",
    "                if tok:\n",
    "                    words.append({\"start\": float(w.start), \"end\": float(w.end), \"text\": tok})\n",
    "    print(f\"[info] words captured: {len(words)}\")\n",
    "\n",
    "    # Build ASS in-memory\n",
    "    _, FONT_NAME = pick_custom_font(CUSTOM_FONT_DIR)\n",
    "    ASS_HEADER = ASS_HEADER_TMPL.format(\n",
    "        play_w=PLAY_W, play_h=PLAY_H, font=FONT_NAME, size=FONT_SIZE,\n",
    "        border=_fmt_float(BORDER_PX), shadow=_fmt_float(SHADOW_PX)\n",
    "    )\n",
    "    caption_lines = group_words_to_captions(words, MAX_WORDS_PER_CAP, MAX_CHARS_PER_CAP, MAX_GAP_SEC)\n",
    "    ass_events = build_center_caption_events(\n",
    "        caption_lines,\n",
    "        play_w=PLAY_W, play_h=PLAY_H,\n",
    "        uppercase=UPPERCASE,\n",
    "        min_caption=MIN_CAPTION_SEC,\n",
    "        cut_ahead=CUT_AHEAD_SEC,\n",
    "        tail_hold=TAIL_HOLD_SEC,\n",
    "        anim=ANIM,\n",
    "        in_ms=ANIM_IN_MS,\n",
    "        out_ms=ANIM_OUT_MS,\n",
    "        border_px=BORDER_PX,\n",
    "        stabilize_outline=STABILIZE_OUTLINE,\n",
    "        blur_px=BLUR_PX\n",
    "    )\n",
    "    ass_text = ASS_HEADER + \"\\n\".join(ass_events)\n",
    "\n",
    "    # Output path (timestamped)\n",
    "    out_dir  = ensure_dir(Path(OUTPUT_DIR))\n",
    "    ts       = timestamp()\n",
    "    out_name = FILENAME_TEMPLATE.format(stem=sanitize_stem(video_path.stem), ts=ts, anim=ANIM)\n",
    "    out_video = (out_dir / out_name).resolve()\n",
    "    out_tmp   = out_video.with_suffix(\".tmp.mp4\")\n",
    "\n",
    "    print(\"[info] OUTPUT_DIR:\", out_dir)\n",
    "    print(\"[info] Will write FINAL:\", out_video)\n",
    "\n",
    "    # Colorspace passthrough to prevent gamma/contrast shifts\n",
    "    color_flags = probe_color_metadata(video_path)\n",
    "    color_list  = [kv for pair in color_flags.items() for kv in pair]\n",
    "    if color_list:\n",
    "        print(\"[info] Color metadata passthrough:\", dict(zip(color_list[::2], color_list[1::2])))\n",
    "\n",
    "    # ffmpeg command\n",
    "    if not shutil.which(\"ffmpeg\"):\n",
    "        raise SystemExit(\"FFmpeg not found on PATH. Install it and rerun.\")\n",
    "    fontsdir_arg = f\":fontsdir={CUSTOM_FONT_DIR.as_posix()}\"\n",
    "\n",
    "    enc_flags   = build_encoder_flags()\n",
    "    audio_flags = [\"-c:a\",\"copy\"] if COPY_AUDIO else [\"-c:a\",\"aac\",\"-b:a\",\"192k\"]\n",
    "\n",
    "    tmp_ass = None\n",
    "    try:\n",
    "        # write temp .ass first so we can insert the real path into -vf\n",
    "        with tempfile.NamedTemporaryFile(\"w\", suffix=\".ass\", delete=False, encoding=\"utf-8\") as tmp:\n",
    "            tmp.write(ass_text)\n",
    "            tmp.flush()\n",
    "            tmp_ass = Path(tmp.name)\n",
    "\n",
    "        # ✅ build the filtergraph *now* with the actual ass path — no f-string placeholder\n",
    "        if YUV444_RENDER:\n",
    "            vf_arg_final = f\"format=yuv444p,ass={tmp_ass.as_posix()}{fontsdir_arg},format=yuv420p\"\n",
    "        else:\n",
    "            vf_arg_final = f\"ass={tmp_ass.as_posix()}{fontsdir_arg}\"\n",
    "\n",
    "        cmd = ([\"ffmpeg\",\"-y\",\"-i\",str(video_path),\n",
    "                \"-vf\", vf_arg_final]\n",
    "               + enc_flags\n",
    "               + audio_flags\n",
    "               + color_list\n",
    "               + [\"-movflags\",\"+faststart\",  # web-friendly\n",
    "                  str(out_tmp)])\n",
    "\n",
    "        print(\"[info] ffmpeg cmd:\\n \", \" \".join(cmd))\n",
    "        run = subprocess.run(cmd, check=False, text=True, capture_output=True)\n",
    "        if run.returncode != 0:\n",
    "            print(run.stderr)\n",
    "            raise RuntimeError(f\"ffmpeg failed (code {run.returncode})\")\n",
    "\n",
    "        out_tmp.replace(out_video)\n",
    "        print(\"[done] saved:\", out_video)\n",
    "\n",
    "    finally:\n",
    "        if tmp_ass and tmp_ass.exists():\n",
    "            try: tmp_ass.unlink()\n",
    "            except Exception as e: print(f\"[warn] could not delete temp ASS: {e}\")\n",
    "        if out_tmp.exists():\n",
    "            try: out_tmp.unlink()\n",
    "            except Exception: pass\n",
    "\n",
    "    if not out_video.exists():\n",
    "        raise FileNotFoundError(f\"Expected output not found: {out_video}\")\n",
    "\n",
    "    return out_video.as_posix()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15df2960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[debug] using beta_captions_v3\n",
      "[info] video: /Users/marcus/Downloads/reddit1_filmora_clipstore/tester88888.mp4\n",
      "[info] PlayRes set to: 1080x1920 | Center=(540,960)\n",
      "[info] loading Whisper model …\n",
      "[info] trying compute_type=float16 …\n",
      "[skip] Requested float16 compute type, but the target device or backend do not support efficient float16 computation.\n",
      "[info] trying compute_type=int8 …\n",
      "[info] transcribing (word timestamps) …\n",
      "[info] words captured: 22\n",
      "[font] Using file: /Users/marcus/Documents/mrbeast_caps/fonts/KOMIKAX_.ttf\n",
      "[font] Font family set to: Komika Axis\n",
      "[info] OUTPUT_DIR: /Users/marcus/Downloads/reddit1_captioned\n",
      "[info] Will write FINAL: /Users/marcus/Downloads/reddit1_captioned/exported_20250905_034133.mp4\n",
      "[info] Color metadata passthrough: {'-color_primaries': 'bt709', '-color_trc': 'bt709', '-colorspace': 'bt709', '-color_range': 'tv'}\n",
      "[info] ffmpeg cmd:\n",
      "  ffmpeg -y -i /Users/marcus/Downloads/reddit1_filmora_clipstore/tester88888.mp4 -vf format=yuv444p,ass=/var/folders/n2/rstg0c3j7hv2shgc8szmsj2r0000gp/T/tmpomff795n.ass:fontsdir=/Users/marcus/Documents/mrbeast_caps/fonts,format=yuv420p -c:v libx264 -preset slow -profile:v high -level:v 4.2 -pix_fmt yuv420p -crf 16 -x264-params aq-mode=2:aq-strength=1.0:ref=5:bframes=5:me=umh:subme=7 -c:a copy -color_primaries bt709 -color_trc bt709 -colorspace bt709 -color_range tv -movflags +faststart /Users/marcus/Downloads/reddit1_captioned/exported_20250905_034133.tmp.mp4\n",
      "[done] saved: /Users/marcus/Downloads/reddit1_captioned/exported_20250905_034133.mp4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Users/marcus/Downloads/reddit1_captioned/exported_20250905_034133.mp4'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "beta_captions_v3(Path.home() / \"Downloads\" / \"reddit1_filmora_clipstore\" / \"tester88888.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efe2b39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
