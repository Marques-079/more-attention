{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4291964d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyautogui\n",
    "import time\n",
    "\n",
    "time.sleep(2.0)\n",
    "pyautogui.rightClick()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fb6eeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CONFIG ==============================================================\n",
    "from pathlib import Path\n",
    "import tempfile\n",
    "# Encoder & quality controls\n",
    "ENCODER      = \"libx264\"   # \"libx264\" (best quality) or \"videotoolbox\" (fast on Mac)\n",
    "CRF          = 16          # 16–18 = visually lossless; bigger = smaller files\n",
    "X264_PRESET  = \"slow\"      # \"slow\" (quality), \"medium\", \"fast\"\n",
    "PROFILE      = \"high\"      # h264 profile\n",
    "LEVEL        = \"4.2\"       # OK for 1080p30/60; adjust if needed\n",
    "COPY_AUDIO   = True        # keep original audio\n",
    "\n",
    "\n",
    "# Where to save the rendered video:\n",
    "OUTPUT_DIR = Path.home() / \"Downloads\" / \"reddit1_captioned\"   # <— change me\n",
    "\n",
    "# Filename pattern (placeholders: {stem}=input filename stem, {ts}=timestamp, {anim}=ANIM)\n",
    "FILENAME_TEMPLATE = \"exported_{ts}.mp4\"\n",
    "\n",
    "\n",
    "#INPUT_VIDEO       = Path.home() / \"Downloads\" / \"reddit1_filmora_clipstore\" / \"tester88888.mp4\"\n",
    "MODEL_NAME        = \"small.en\"       # tiny/base/small/medium/large-v3; *.en faster for English\n",
    "\n",
    "# Caption look\n",
    "FONT_SIZE         = 210\n",
    "UPPERCASE         = True\n",
    "\n",
    "# Outline controls\n",
    "BORDER_PX         = 12.0             # base outline thickness (px)\n",
    "SHADOW_PX         = 2.0              # shadow strength\n",
    "BLUR_PX           = 0.0              # small blur reduces shimmer; try 0.3–0.8 if edges flicker\n",
    "STABILIZE_OUTLINE = True             # <<< turn this on to animate \\bord with scale\n",
    "\n",
    "# Timing hyperparams\n",
    "MIN_CAPTION_SEC   = 0.30\n",
    "CUT_AHEAD_SEC     = 0.00\n",
    "TAIL_HOLD_SEC     = 1.20\n",
    "\n",
    "# Grouping hyperparams (control words/characters per caption)\n",
    "MAX_WORDS_PER_CAP = 1\n",
    "MAX_CHARS_PER_CAP = None\n",
    "MAX_GAP_SEC       = 1.20\n",
    "\n",
    "# Animation\n",
    "# ANIM choices: \"none\",\"fade\",\"pop\",\"zoom\",\"bounce\",\"slide_up\",\"slide_down\",\n",
    "#               \"slide_left\",\"slide_right\",\"rotate\",\"inflate\",\"inflate_soft\"\n",
    "ANIM              = \"inflate\"\n",
    "ANIM_IN_MS        = 20000   # your original long ramp; try 200–400 for subtle pop\n",
    "ANIM_OUT_MS       = 50\n",
    "\n",
    "# Fonts\n",
    "CUSTOM_FONT_DIR   = Path.home() / \"Documents\" / \"mrbeast_caps\" / \"fonts\"\n",
    "\n",
    "# Rendering safety\n",
    "AUTO_PLAYRES      = True             # match ASS PlayRes to actual video resolution\n",
    "YUV444_RENDER     = True             # render subs in 4:4:4 to stabilize edges, then downsample\n",
    "# ========================================================================\n",
    "\n",
    "def probe_color_metadata(video_path: Path):\n",
    "    \"\"\"\n",
    "    Return dict with color_primaries, color_trc, colorspace, color_range (tv/pc) if present.\n",
    "    Prevents gamma/contrast shifts after burn-in.\n",
    "    \"\"\"\n",
    "    import json, subprocess\n",
    "    cmd = [\n",
    "        \"ffprobe\",\"-v\",\"error\",\"-select_streams\",\"v:0\",\n",
    "        \"-show_entries\",\"stream=color_primaries,color_transfer,color_space,color_range\",\n",
    "        \"-of\",\"json\", str(video_path)\n",
    "    ]\n",
    "    try:\n",
    "        data = json.loads(subprocess.check_output(cmd, text=True))\n",
    "        st = (data.get(\"streams\") or [{}])[0]\n",
    "        prim = st.get(\"color_primaries\")\n",
    "        trc  = st.get(\"color_transfer\")\n",
    "        spc  = st.get(\"color_space\")\n",
    "        rng  = st.get(\"color_range\")  # \"tv\" or \"pc\"\n",
    "        # Map ffprobe keys to ffmpeg options\n",
    "        out = {}\n",
    "        if prim: out[\"-color_primaries\"] = prim\n",
    "        if trc:  out[\"-color_trc\"]       = trc\n",
    "        if spc:  out[\"-colorspace\"]      = spc\n",
    "        if rng:  out[\"-color_range\"]     = rng\n",
    "        return out\n",
    "    except Exception:\n",
    "        return {}\n",
    "\n",
    "def build_encoder_flags():\n",
    "    \"\"\"\n",
    "    Choose encoder args for best visual fidelity.\n",
    "    \"\"\"\n",
    "    flags = []\n",
    "    if ENCODER == \"libx264\":\n",
    "        flags += [\"-c:v\",\"libx264\",\n",
    "                  \"-preset\", X264_PRESET,\n",
    "                  \"-profile:v\", PROFILE,\n",
    "                  \"-level:v\", LEVEL,\n",
    "                  \"-pix_fmt\",\"yuv420p\",\n",
    "                  \"-crf\", str(CRF)]\n",
    "        # Reasonable x264 params for detail retention without going crazy:\n",
    "        flags += [\"-x264-params\", \"aq-mode=2:aq-strength=1.0:ref=5:bframes=5:me=umh:subme=7\"]\n",
    "    else:  # \"videotoolbox\" (fast; OK quality if CRF ~18)\n",
    "        flags += [\"-c:v\",\"h264_videotoolbox\",\n",
    "                  \"-profile:v\", PROFILE,\n",
    "                  \"-pix_fmt\",\"yuv420p\",\n",
    "                  \"-crf\", str(CRF),\n",
    "                  \"-allow_sw\",\"1\"]\n",
    "    return flags\n",
    "\n",
    "\n",
    "\n",
    "import os, subprocess, shutil, platform, re, sys\n",
    "from datetime import timedelta\n",
    "from faster_whisper import WhisperModel\n",
    "import re\n",
    "from datetime import datetime \n",
    "\n",
    "def timestamp(fmt: str = \"%Y%m%d_%H%M%S\") -> str:\n",
    "    \"\"\"Current local time formatted for filenames.\"\"\"\n",
    "    return datetime.now().strftime(fmt)\n",
    "\n",
    "def sanitize_stem(stem: str) -> str:\n",
    "    \"\"\"Make a filesystem-safe stem.\"\"\"\n",
    "    return re.sub(r'[^A-Za-z0-9_.-]+', '_', stem).strip('_')\n",
    "\n",
    "def ensure_dir(p: Path) -> Path:\n",
    "    \"\"\"Create directory if needed and return it.\"\"\"\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "    return p\n",
    "\n",
    "\n",
    "# ---------- probe video resolution ----------\n",
    "def probe_resolution(video_path: Path) -> tuple[int, int]:\n",
    "    cmd = [\n",
    "        \"ffprobe\",\"-v\",\"error\",\"-select_streams\",\"v:0\",\n",
    "        \"-show_entries\",\"stream=width,height\",\"-of\",\"csv=s=x:p=0\", str(video_path)\n",
    "    ]\n",
    "    try:\n",
    "        out = subprocess.check_output(cmd, text=True).strip()\n",
    "        w, h = map(int, out.split(\"x\"))\n",
    "        return w, h\n",
    "    except Exception:\n",
    "        # fallback\n",
    "        return 1920, 1080\n",
    "\n",
    "# centers derived later once we know resolution\n",
    "CENTER_X, CENTER_Y = None, None\n",
    "\n",
    "# ---------- load Whisper with a supported compute_type ----------\n",
    "import platform as _pf\n",
    "def load_whisper_auto(model_name: str):\n",
    "    osname = _pf.system()\n",
    "    candidates = ([\"float16\", \"int8\", \"float32\"] if osname == \"Darwin\"\n",
    "                  else [\"int8_float16\", \"int8\", \"float16\", \"float32\"])\n",
    "    last = None\n",
    "    for ct in candidates:\n",
    "        try:\n",
    "            print(f\"[info] trying compute_type={ct} …\")\n",
    "            return WhisperModel(model_name, compute_type=ct, device=\"auto\")\n",
    "        except ValueError as e:\n",
    "            print(f\"[skip] {e}\")\n",
    "            last = e\n",
    "    raise last\n",
    "\n",
    "# ---------- font: use any .ttf/.otf in CUSTOM_FONT_DIR ----------\n",
    "def pick_custom_font(font_dir: Path):\n",
    "    font_dir.mkdir(parents=True, exist_ok=True)\n",
    "    candidates = list(font_dir.glob(\"*.ttf\")) + list(font_dir.glob(\"*.otf\"))\n",
    "    if not candidates:\n",
    "        print(\"\\n[FONT SETUP REQUIRED]\")\n",
    "        print(\"1) Download any .ttf or .otf font.\")\n",
    "        print(f\"2) Place it here: {font_dir}\")\n",
    "        print(\"3) Re-run.\")\n",
    "        raise SystemExit(\"[exit] No font found yet.\")\n",
    "    font_file = candidates[0]\n",
    "    family = None\n",
    "    try:\n",
    "        from fontTools.ttLib import TTFont  # optional (pip install fonttools)\n",
    "        tt = TTFont(font_file)\n",
    "        names = {n.nameID: n.toUnicode() for n in tt[\"name\"].names if n.toUnicode()}\n",
    "        family = names.get(1) or names.get(4)\n",
    "    except Exception:\n",
    "        family = font_file.stem\n",
    "    print(\"[font] Using file:\", font_file)\n",
    "    print(\"[font] Font family set to:\", family)\n",
    "    return font_file, family\n",
    "\n",
    "# ---------- ASS header template (filled later with resolution) ----------\n",
    "ASS_HEADER_TMPL = \"\"\"[Script Info]\n",
    "ScriptType: v4.00+\n",
    "PlayResX: {play_w}\n",
    "PlayResY: {play_h}\n",
    "ScaledBorderAndShadow: yes\n",
    "WrapStyle: 2\n",
    "\n",
    "[V4+ Styles]\n",
    "Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding\n",
    "; White text (Primary), THICK black outline, subtle shadow for separation.\n",
    "Style: Beast,{font},{size},&H00FFFFFF,&H00FFFFFF,&H00000000,&H64000000,-1,0,0,0,100,100,0,0,1,{border},{shadow},5,60,60,60,1\n",
    "\n",
    "[Events]\n",
    "Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text\n",
    "\"\"\"\n",
    "\n",
    "def _fmt_time(t: float) -> str:\n",
    "    td = timedelta(seconds=max(0.0, t))\n",
    "    cs = int(round(td.total_seconds() * 100))\n",
    "    h, rem = divmod(cs, 360000)\n",
    "    m, rem = divmod(rem, 6000)\n",
    "    s, cs = divmod(rem, 100)\n",
    "    return f\"{h}:{m:02d}:{s:02d}.{cs:02d}\"\n",
    "\n",
    "# compute start/end scales & animated \\bord when stabilizing\n",
    "def _scale_spec_for_anim(name: str):\n",
    "    name = (name or \"none\").lower()\n",
    "    # start_scale, end_scale\n",
    "    if name in (\"inflate\", \"inflate_soft\", \"pop\"):\n",
    "        return 80, 100\n",
    "    if name == \"zoom\":\n",
    "        return 60, 100\n",
    "    # slide/rotate/fade/none: no scale change\n",
    "    return 100, 100\n",
    "\n",
    "def _fmt_float(x: float) -> str:\n",
    "    # compact float formatting for ASS tags\n",
    "    return f\"{x:.2f}\".rstrip(\"0\").rstrip(\".\")\n",
    "\n",
    "def anim_tag(cx: int, cy: int, name: str, in_ms: int, out_ms: int,\n",
    "             border_px: float, stabilize_outline: bool, blur_px: float) -> str:\n",
    "    # snap to pixel to reduce subpixel shimmer\n",
    "    cx, cy = int(round(cx)), int(round(cy))\n",
    "    s0, s1 = _scale_spec_for_anim(name)\n",
    "    # outline start/end if stabilizing (inverse proportional to scale)\n",
    "    if stabilize_outline and (s0 != s1):\n",
    "        bord0 = border_px * (s0 / 100.0)\n",
    "        bord1 = border_px * (s1 / 100.0)\n",
    "        bord_tag0 = rf\"\\bord{_fmt_float(bord0)}\"\n",
    "        bord_anim = rf\"\\t(0,{in_ms},\\bord{_fmt_float(bord1)})\"\n",
    "    else:\n",
    "        bord0 = border_px\n",
    "        bord_tag0 = rf\"\\bord{_fmt_float(bord0)}\"\n",
    "        bord_anim = \"\"\n",
    "\n",
    "    blur_tag = (rf\"\\blur{_fmt_float(blur_px)}\" if blur_px and blur_px > 0 else \"\")\n",
    "\n",
    "    name = (name or \"none\").lower()\n",
    "    if name == \"none\":\n",
    "        return rf\"{{\\an5\\pos({cx},{cy}){bord_tag0}{blur_tag}}}\"\n",
    "    if name == \"fade\":\n",
    "        return rf\"{{\\an5\\pos({cx},{cy}){bord_tag0}{blur_tag}\\fad({in_ms},{out_ms})}}\"\n",
    "    if name == \"pop\":\n",
    "        return rf\"{{\\an5\\pos({cx},{cy}){bord_tag0}{blur_tag}\\fscx80\\fscy80\\t(0,{in_ms},\\fscx100\\fscy100){bord_anim}}}\"\n",
    "    if name == \"zoom\":\n",
    "        return rf\"{{\\an5\\pos({cx},{cy}){bord_tag0}{blur_tag}\\fscx60\\fscy60\\t(0,{in_ms},\\fscx100\\fscy100){bord_anim}}}\"\n",
    "    if name == \"bounce\":\n",
    "        return (rf\"{{\\an5\\move({cx},{cy-40},{cx},{cy},0,{in_ms}){bord_tag0}{blur_tag}\"\n",
    "                rf\"\\fscx120\\fscy120\\t(0,120,\\fscx95\\fscy95)\\t(120,{in_ms},\\fscx100\\fscy100){bord_anim}}}\")\n",
    "    if name == \"slide_up\":\n",
    "        return rf\"{{\\an5\\move({cx},{cy+60},{cx},{cy},0,{in_ms}){bord_tag0}{blur_tag}}}\"\n",
    "    if name == \"slide_down\":\n",
    "        return rf\"{{\\an5\\move({cx},{cy-60},{cx},{cy},0,{in_ms}){bord_tag0}{blur_tag}}}\"\n",
    "    if name == \"slide_left\":\n",
    "        return rf\"{{\\an5\\move({cx-140},{cy},{cx},{cy},0,{in_ms}){bord_tag0}{blur_tag}}}\"\n",
    "    if name == \"slide_right\":\n",
    "        return rf\"{{\\an5\\move({cx+140},{cy},{cx},{cy},0,{in_ms}){bord_tag0}{blur_tag}}}\"\n",
    "    if name == \"rotate\":\n",
    "        return rf\"{{\\an5\\pos({cx},{cy}){bord_tag0}{blur_tag}\\frz-12\\t(0,{in_ms},\\frz0)}}\"\n",
    "    if name == \"inflate\":\n",
    "        return rf\"{{\\an5\\pos({cx},{cy}){bord_tag0}{blur_tag}\\fscx80\\fscy80\\t(0,{in_ms},\\fscx100\\fscy100){bord_anim}}}\"\n",
    "    if name == \"inflate_soft\":\n",
    "        return (rf\"{{\\an5\\pos({cx},{cy}){bord_tag0}{blur_tag}\\fscx80\\fscy80\\alpha&H20&\\blur2\"\n",
    "                rf\"\\t(0,{in_ms},\\fscx100\\fscy100\\alpha&H00&\\blur0){bord_anim}}}\")\n",
    "    return rf\"{{\\an5\\pos({cx},{cy}){bord_tag0}{blur_tag}}}\"\n",
    "\n",
    "# ---------- Group words into captions ----------\n",
    "def clean_token(s: str) -> str:\n",
    "    s = (s or \"\").strip()\n",
    "    s = re.sub(r\"^\\s+|\\s+$\", \"\", s)\n",
    "    return re.sub(r\"^\\W+|\\W+$\", \"\", s)\n",
    "\n",
    "def group_words_to_captions(words,\n",
    "                            max_words=1,\n",
    "                            max_chars=None,\n",
    "                            max_gap_s=0.6):\n",
    "    lines, cur = [], []\n",
    "    last_end = None\n",
    "    for w in words:\n",
    "        token = clean_token(w[\"text\"])\n",
    "        if not token:\n",
    "            continue\n",
    "        gap = (w[\"start\"] - last_end) if last_end is not None else 0.0\n",
    "\n",
    "        join_len = len((\" \".join([x[\"text\"] for x in cur] + [token])).strip())\n",
    "        need_new = False\n",
    "        if last_end is not None and gap > max_gap_s:\n",
    "            need_new = True\n",
    "        if cur and len(cur) >= max_words:\n",
    "            need_new = True\n",
    "        if (not need_new) and (max_chars is not None) and (join_len > max_chars):\n",
    "            need_new = True\n",
    "\n",
    "        if need_new and cur:\n",
    "            lines.append(cur)\n",
    "            cur = []\n",
    "\n",
    "        cur.append({\"start\": float(w[\"start\"]), \"end\": float(w[\"end\"]), \"text\": token})\n",
    "        last_end = float(w[\"end\"])\n",
    "\n",
    "    if cur:\n",
    "        lines.append(cur)\n",
    "    return lines\n",
    "\n",
    "def build_center_caption_events(lines,\n",
    "                                play_w: int, play_h: int,\n",
    "                                uppercase=True,\n",
    "                                min_caption=0.30,\n",
    "                                cut_ahead=0.00,\n",
    "                                tail_hold=1.20,\n",
    "                                anim=\"none\",\n",
    "                                in_ms=220,\n",
    "                                out_ms=100,\n",
    "                                border_px=12.0,\n",
    "                                stabilize_outline=True,\n",
    "                                blur_px=0.0):\n",
    "    cx = int(round(play_w / 2))\n",
    "    cy = int(round(play_h / 2))\n",
    "    events = []\n",
    "    n = len(lines)\n",
    "    for i, ln in enumerate(lines):\n",
    "        t0 = float(ln[0][\"start\"])\n",
    "        natural_end = float(ln[-1][\"end\"])\n",
    "        t1 = max(natural_end, t0 + min_caption)\n",
    "\n",
    "        if i + 1 < n:\n",
    "            next_start = float(lines[i+1][0][\"start\"])\n",
    "            gap_after = max(0.0, next_start - natural_end - cut_ahead)\n",
    "            t1 = min(max(t1, natural_end + min(tail_hold, gap_after)), next_start - cut_ahead)\n",
    "        else:\n",
    "            t1 = max(natural_end + tail_hold, t0 + min_caption)\n",
    "\n",
    "        if t1 <= t0:\n",
    "            t1 = t0 + 0.05\n",
    "\n",
    "        text = \" \".join([w[\"text\"] for w in ln]).strip()\n",
    "        if uppercase:\n",
    "            text = text.upper()\n",
    "\n",
    "        ov = anim_tag(cx, cy, anim, in_ms, out_ms, border_px, stabilize_outline, blur_px)\n",
    "        events.append(f\"Dialogue: 0,{_fmt_time(t0)},{_fmt_time(t1)},Beast,,0,0,0,,{ov}{text}\")\n",
    "    return events\n",
    "import subprocess, shutil, platform, tempfile, inspect\n",
    "\n",
    "\n",
    "import subprocess, shutil, platform, tempfile, inspect\n",
    "\n",
    "def beta_captions_v3(INPUT_VIDEO) -> str:\n",
    "    print(f\"[debug] using {inspect.currentframe().f_code.co_name}\")\n",
    "\n",
    "    video_path = Path(INPUT_VIDEO).expanduser().resolve()\n",
    "    assert video_path.exists(), f\"Video not found: {video_path}\"\n",
    "    print(\"[info] video:\", video_path)\n",
    "\n",
    "    # Resolution & center\n",
    "    PLAY_W, PLAY_H = probe_resolution(video_path) if AUTO_PLAYRES else (1920, 1080)\n",
    "    cx, cy = (PLAY_W // 2, PLAY_H // 2) if (CENTER_X is None or CENTER_Y is None) else (CENTER_X, CENTER_Y)\n",
    "    print(f\"[info] PlayRes set to: {PLAY_W}x{PLAY_H} | Center=({cx},{cy})\")\n",
    "\n",
    "    # Transcribe\n",
    "    print(\"[info] loading Whisper model …\")\n",
    "    model = load_whisper_auto(MODEL_NAME)\n",
    "    print(\"[info] transcribing (word timestamps) …\")\n",
    "    segments, _ = model.transcribe(str(video_path), vad_filter=True, word_timestamps=True)\n",
    "\n",
    "    words = []\n",
    "    for seg in segments:\n",
    "        if seg.words:\n",
    "            for w in seg.words:\n",
    "                tok = (w.word or \"\").strip()\n",
    "                if tok:\n",
    "                    words.append({\"start\": float(w.start), \"end\": float(w.end), \"text\": tok})\n",
    "    print(f\"[info] words captured: {len(words)}\")\n",
    "\n",
    "    # Build ASS in-memory\n",
    "    _, FONT_NAME = pick_custom_font(CUSTOM_FONT_DIR)\n",
    "    ASS_HEADER = ASS_HEADER_TMPL.format(\n",
    "        play_w=PLAY_W, play_h=PLAY_H, font=FONT_NAME, size=FONT_SIZE,\n",
    "        border=_fmt_float(BORDER_PX), shadow=_fmt_float(SHADOW_PX)\n",
    "    )\n",
    "    caption_lines = group_words_to_captions(words, MAX_WORDS_PER_CAP, MAX_CHARS_PER_CAP, MAX_GAP_SEC)\n",
    "    ass_events = build_center_caption_events(\n",
    "        caption_lines,\n",
    "        play_w=PLAY_W, play_h=PLAY_H,\n",
    "        uppercase=UPPERCASE,\n",
    "        min_caption=MIN_CAPTION_SEC,\n",
    "        cut_ahead=CUT_AHEAD_SEC,\n",
    "        tail_hold=TAIL_HOLD_SEC,\n",
    "        anim=ANIM,\n",
    "        in_ms=ANIM_IN_MS,\n",
    "        out_ms=ANIM_OUT_MS,\n",
    "        border_px=BORDER_PX,\n",
    "        stabilize_outline=STABILIZE_OUTLINE,\n",
    "        blur_px=BLUR_PX\n",
    "    )\n",
    "    ass_text = ASS_HEADER + \"\\n\".join(ass_events)\n",
    "\n",
    "    # Output path (timestamped)\n",
    "    out_dir  = ensure_dir(Path(OUTPUT_DIR))\n",
    "    ts       = timestamp()\n",
    "    out_name = FILENAME_TEMPLATE.format(stem=sanitize_stem(video_path.stem), ts=ts, anim=ANIM)\n",
    "    out_video = (out_dir / out_name).resolve()\n",
    "    out_tmp   = out_video.with_suffix(\".tmp.mp4\")\n",
    "\n",
    "    print(\"[info] OUTPUT_DIR:\", out_dir)\n",
    "    print(\"[info] Will write FINAL:\", out_video)\n",
    "\n",
    "    # Colorspace passthrough to prevent gamma/contrast shifts\n",
    "    color_flags = probe_color_metadata(video_path)\n",
    "    color_list  = [kv for pair in color_flags.items() for kv in pair]\n",
    "    if color_list:\n",
    "        print(\"[info] Color metadata passthrough:\", dict(zip(color_list[::2], color_list[1::2])))\n",
    "\n",
    "    # ffmpeg command\n",
    "    if not shutil.which(\"ffmpeg\"):\n",
    "        raise SystemExit(\"FFmpeg not found on PATH. Install it and rerun.\")\n",
    "    fontsdir_arg = f\":fontsdir={CUSTOM_FONT_DIR.as_posix()}\"\n",
    "\n",
    "    enc_flags   = build_encoder_flags()\n",
    "    audio_flags = [\"-c:a\",\"copy\"] if COPY_AUDIO else [\"-c:a\",\"aac\",\"-b:a\",\"192k\"]\n",
    "\n",
    "    tmp_ass = None\n",
    "    try:\n",
    "        # write temp .ass first so we can insert the real path into -vf\n",
    "        with tempfile.NamedTemporaryFile(\"w\", suffix=\".ass\", delete=False, encoding=\"utf-8\") as tmp:\n",
    "            tmp.write(ass_text)\n",
    "            tmp.flush()\n",
    "            tmp_ass = Path(tmp.name)\n",
    "\n",
    "        # ✅ build the filtergraph *now* with the actual ass path — no f-string placeholder\n",
    "        if YUV444_RENDER:\n",
    "            vf_arg_final = f\"format=yuv444p,ass={tmp_ass.as_posix()}{fontsdir_arg},format=yuv420p\"\n",
    "        else:\n",
    "            vf_arg_final = f\"ass={tmp_ass.as_posix()}{fontsdir_arg}\"\n",
    "\n",
    "        cmd = ([\"ffmpeg\",\"-y\",\"-i\",str(video_path),\n",
    "                \"-vf\", vf_arg_final]\n",
    "               + enc_flags\n",
    "               + audio_flags\n",
    "               + color_list\n",
    "               + [\"-movflags\",\"+faststart\",  # web-friendly\n",
    "                  str(out_tmp)])\n",
    "\n",
    "        print(\"[info] ffmpeg cmd:\\n \", \" \".join(cmd))\n",
    "        run = subprocess.run(cmd, check=False, text=True, capture_output=True)\n",
    "        if run.returncode != 0:\n",
    "            print(run.stderr)\n",
    "            raise RuntimeError(f\"ffmpeg failed (code {run.returncode})\")\n",
    "\n",
    "        out_tmp.replace(out_video)\n",
    "        print(\"[done] saved:\", out_video)\n",
    "\n",
    "    finally:\n",
    "        if tmp_ass and tmp_ass.exists():\n",
    "            try: tmp_ass.unlink()\n",
    "            except Exception as e: print(f\"[warn] could not delete temp ASS: {e}\")\n",
    "        if out_tmp.exists():\n",
    "            try: out_tmp.unlink()\n",
    "            except Exception: pass\n",
    "\n",
    "    if not out_video.exists():\n",
    "        raise FileNotFoundError(f\"Expected output not found: {out_video}\")\n",
    "\n",
    "    return out_video.as_posix()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15df2960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[debug] using beta_captions_v3\n",
      "[info] video: /Users/marcus/Downloads/reddit1_filmora_clipstore/tester88888.mp4\n",
      "[info] PlayRes set to: 1080x1920 | Center=(540,960)\n",
      "[info] loading Whisper model …\n",
      "[info] trying compute_type=float16 …\n",
      "[skip] Requested float16 compute type, but the target device or backend do not support efficient float16 computation.\n",
      "[info] trying compute_type=int8 …\n",
      "[info] transcribing (word timestamps) …\n",
      "[info] words captured: 22\n",
      "[font] Using file: /Users/marcus/Documents/mrbeast_caps/fonts/KOMIKAX_.ttf\n",
      "[font] Font family set to: Komika Axis\n",
      "[info] OUTPUT_DIR: /Users/marcus/Downloads/reddit1_captioned\n",
      "[info] Will write FINAL: /Users/marcus/Downloads/reddit1_captioned/exported_20250905_034133.mp4\n",
      "[info] Color metadata passthrough: {'-color_primaries': 'bt709', '-color_trc': 'bt709', '-colorspace': 'bt709', '-color_range': 'tv'}\n",
      "[info] ffmpeg cmd:\n",
      "  ffmpeg -y -i /Users/marcus/Downloads/reddit1_filmora_clipstore/tester88888.mp4 -vf format=yuv444p,ass=/var/folders/n2/rstg0c3j7hv2shgc8szmsj2r0000gp/T/tmpomff795n.ass:fontsdir=/Users/marcus/Documents/mrbeast_caps/fonts,format=yuv420p -c:v libx264 -preset slow -profile:v high -level:v 4.2 -pix_fmt yuv420p -crf 16 -x264-params aq-mode=2:aq-strength=1.0:ref=5:bframes=5:me=umh:subme=7 -c:a copy -color_primaries bt709 -color_trc bt709 -colorspace bt709 -color_range tv -movflags +faststart /Users/marcus/Downloads/reddit1_captioned/exported_20250905_034133.tmp.mp4\n",
      "[done] saved: /Users/marcus/Downloads/reddit1_captioned/exported_20250905_034133.mp4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Users/marcus/Downloads/reddit1_captioned/exported_20250905_034133.mp4'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "beta_captions_v3(Path.home() / \"Downloads\" / \"reddit1_filmora_clipstore\" / \"tester88888.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5efe2b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CONFIG ==============================================================\n",
    "\n",
    "from pathlib import Path\n",
    "import tempfile\n",
    "\n",
    "# Where to save the rendered video:\n",
    "OUTPUT_DIR = Path.home() / \"Downloads\" / \"reddit1_filmora_captioned\"\n",
    "\n",
    "# Filename pattern (placeholders: {stem}=input filename stem, {ts}=timestamp, {anim}=ANIM)\n",
    "FILENAME_TEMPLATE = \"exported_{ts}.mp4\"\n",
    "\n",
    "MODEL_NAME        = \"small.en\"       # tiny/base/small/medium/large-v3; *.en faster for English\n",
    "\n",
    "# Caption look\n",
    "FONT_SIZE         = 210\n",
    "UPPERCASE         = True\n",
    "\n",
    "# Outline controls\n",
    "BORDER_PX         = 12.0\n",
    "SHADOW_PX         = 2.0\n",
    "BLUR_PX           = 0.0\n",
    "STABILIZE_OUTLINE = True\n",
    "\n",
    "# Timing hyperparams\n",
    "MIN_CAPTION_SEC   = 0.30\n",
    "CUT_AHEAD_SEC     = 0.00\n",
    "TAIL_HOLD_SEC     = 1.20\n",
    "\n",
    "# Grouping hyperparams\n",
    "MAX_WORDS_PER_CAP = 1\n",
    "MAX_CHARS_PER_CAP = None\n",
    "MAX_GAP_SEC       = 1.20\n",
    "\n",
    "# Animation\n",
    "ANIM              = \"inflate\"\n",
    "ANIM_IN_MS        = 20000\n",
    "ANIM_OUT_MS       = 50\n",
    "\n",
    "# Fonts\n",
    "CUSTOM_FONT_DIR   = Path.home() / \"Documents\" / \"mrbeast_caps\" / \"fonts\"\n",
    "\n",
    "# Rendering safety\n",
    "AUTO_PLAYRES      = True             # match ASS PlayRes to actual video resolution\n",
    "YUV444_RENDER     = True             # render subs in 4:4:4 to stabilize edges, then downsample\n",
    "\n",
    "# --- NEW: Reddit intro card overlay --------------------------------------\n",
    "# You can set this to a FILE or a FOLDER. If it's a folder, the first image is used.\n",
    "# Example folder you mentioned:\n",
    "INTRO_CARD_SRC     = Path(\"/Users/marcus/Downloads/Thumb_shorts_white\")   # or None to disable\n",
    "INTRO_ENABLED      = True            # quick master toggle\n",
    "INTRO_SECS         = 3.0             # how long the card sits on top\n",
    "INTRO_FADE         = 0.30            # fade-out duration (must be <= INTRO_SECS)\n",
    "INTRO_SCALE        = 0.92            # fraction of main video width\n",
    "INTRO_CROP_BOTTOM  = 0.12            # crop bottom % of card (0.0..1.0); 0.12 = remove 12% from bottom\n",
    "INTRO_OFFSET_X     = 0               # px offset from centered X (positive => right)\n",
    "INTRO_OFFSET_Y     = 0               # px offset from centered Y (positive => down)\n",
    "# ========================================================================\n",
    "\n",
    "import os, subprocess, shutil, platform, re, sys\n",
    "from datetime import timedelta\n",
    "from faster_whisper import WhisperModel\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "def timestamp(fmt: str = \"%Y%m%d_%H%M%S\") -> str:\n",
    "    return datetime.now().strftime(fmt)\n",
    "\n",
    "def sanitize_stem(stem: str) -> str:\n",
    "    return re.sub(r'[^A-Za-z0-9_.-]+', '_', stem).strip('_')\n",
    "\n",
    "def ensure_dir(p: Path) -> Path:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "    return p\n",
    "\n",
    "# ---------- probe video resolution ----------\n",
    "def probe_resolution(video_path: Path) -> tuple[int, int]:\n",
    "    cmd = [\n",
    "        \"ffprobe\",\"-v\",\"error\",\"-select_streams\",\"v:0\",\n",
    "        \"-show_entries\",\"stream=width,height\",\"-of\",\"csv=s=x:p=0\", str(video_path)\n",
    "    ]\n",
    "    try:\n",
    "        out = subprocess.check_output(cmd, text=True).strip()\n",
    "        w, h = map(int, out.split(\"x\"))\n",
    "        return w, h\n",
    "    except Exception:\n",
    "        return 1920, 1080\n",
    "\n",
    "CENTER_X, CENTER_Y = None, None\n",
    "\n",
    "# ---------- load Whisper with a supported compute_type ----------\n",
    "import platform as _pf\n",
    "def load_whisper_auto(model_name: str):\n",
    "    osname = _pf.system()\n",
    "    candidates = ([\"float16\", \"int8\", \"float32\"] if osname == \"Darwin\"\n",
    "                  else [\"int8_float16\", \"int8\", \"float16\", \"float32\"])\n",
    "    last = None\n",
    "    for ct in candidates:\n",
    "        try:\n",
    "            print(f\"[info] trying compute_type={ct} …\")\n",
    "            return WhisperModel(model_name, compute_type=ct, device=\"auto\")\n",
    "        except ValueError as e:\n",
    "            print(f\"[skip] {e}\")\n",
    "            last = e\n",
    "    raise last\n",
    "\n",
    "# ---------- font: use any .ttf/.otf in CUSTOM_FONT_DIR ----------\n",
    "def pick_custom_font(font_dir: Path):\n",
    "    font_dir.mkdir(parents=True, exist_ok=True)\n",
    "    candidates = list(font_dir.glob(\"*.ttf\")) + list(font_dir.glob(\"*.otf\"))\n",
    "    if not candidates:\n",
    "        print(\"\\n[FONT SETUP REQUIRED]\")\n",
    "        print(\"1) Download any .ttf or .otf font.\")\n",
    "        print(f\"2) Place it here: {font_dir}\")\n",
    "        print(\"3) Re-run.\")\n",
    "        raise SystemExit(\"[exit] No font found yet.\")\n",
    "    font_file = candidates[0]\n",
    "    family = None\n",
    "    try:\n",
    "        from fontTools.ttLib import TTFont  # optional (pip install fonttools)\n",
    "        tt = TTFont(font_file)\n",
    "        names = {n.nameID: n.toUnicode() for n in tt[\"name\"].names if n.toUnicode()}\n",
    "        family = names.get(1) or names.get(4)\n",
    "    except Exception:\n",
    "        family = font_file.stem\n",
    "    print(\"[font] Using file:\", font_file)\n",
    "    print(\"[font] Font family set to:\", family)\n",
    "    return font_file, family\n",
    "\n",
    "# ---------- ASS header ----------\n",
    "ASS_HEADER_TMPL = \"\"\"[Script Info]\n",
    "ScriptType: v4.00+\n",
    "PlayResX: {play_w}\n",
    "PlayResY: {play_h}\n",
    "ScaledBorderAndShadow: yes\n",
    "WrapStyle: 2\n",
    "\n",
    "[V4+ Styles]\n",
    "Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding\n",
    "; White text (Primary), THICK black outline, subtle shadow for separation.\n",
    "Style: Beast,{font},{size},&H00FFFFFF,&H00FFFFFF,&H00000000,&H64000000,-1,0,0,0,100,100,0,0,1,{border},{shadow},5,60,60,60,1\n",
    "\n",
    "[Events]\n",
    "Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text\n",
    "\"\"\"\n",
    "\n",
    "def _fmt_time(t: float) -> str:\n",
    "    td = timedelta(seconds=max(0.0, t))\n",
    "    cs = int(round(td.total_seconds() * 100))\n",
    "    h, rem = divmod(cs, 360000)\n",
    "    m, rem = divmod(rem, 6000)\n",
    "    s, cs = divmod(rem, 100)\n",
    "    return f\"{h}:{m:02d}:{s:02d}.{cs:02d}\"\n",
    "\n",
    "def _scale_spec_for_anim(name: str):\n",
    "    name = (name or \"none\").lower()\n",
    "    if name in (\"inflate\", \"inflate_soft\", \"pop\"):\n",
    "        return 80, 100\n",
    "    if name == \"zoom\":\n",
    "        return 60, 100\n",
    "    return 100, 100\n",
    "\n",
    "def _fmt_float(x: float) -> str:\n",
    "    return f\"{x:.2f}\".rstrip(\"0\").rstrip(\".\")\n",
    "\n",
    "def anim_tag(cx: int, cy: int, name: str, in_ms: int, out_ms: int,\n",
    "             border_px: float, stabilize_outline: bool, blur_px: float) -> str:\n",
    "    cx, cy = int(round(cx)), int(round(cy))\n",
    "    s0, s1 = _scale_spec_for_anim(name)\n",
    "    if stabilize_outline and (s0 != s1):\n",
    "        bord0 = border_px * (s0 / 100.0)\n",
    "        bord1 = border_px * (s1 / 100.0)\n",
    "        bord_tag0 = rf\"\\bord{_fmt_float(bord0)}\"\n",
    "        bord_anim = rf\"\\t(0,{in_ms},\\bord{_fmt_float(bord1)})\"\n",
    "    else:\n",
    "        bord_tag0 = rf\"\\bord{_fmt_float(border_px)}\"\n",
    "        bord_anim = \"\"\n",
    "    blur_tag = (rf\"\\blur{_fmt_float(blur_px)}\" if blur_px and blur_px > 0 else \"\")\n",
    "    name = (name or \"none\").lower()\n",
    "    if name == \"none\":\n",
    "        return rf\"{{\\an5\\pos({cx},{cy}){bord_tag0}{blur_tag}}}\"\n",
    "    if name == \"fade\":\n",
    "        return rf\"{{\\an5\\pos({cx},{cy}){bord_tag0}{blur_tag}\\fad({in_ms},{out_ms})}}\"\n",
    "    if name == \"pop\":\n",
    "        return rf\"{{\\an5\\pos({cx},{cy}){bord_tag0}{blur_tag}\\fscx80\\fscy80\\t(0,{in_ms},\\fscx100\\fscy100){bord_anim}}}\"\n",
    "    if name == \"zoom\":\n",
    "        return rf\"{{\\an5\\pos({cx},{cy}){bord_tag0}{blur_tag}\\fscx60\\fscy60\\t(0,{in_ms},\\fscx100\\fscy100){bord_anim}}}\"\n",
    "    if name == \"bounce\":\n",
    "        return (rf\"{{\\an5\\move({cx},{cy-40},{cx},{cy},0,{in_ms}){bord_tag0}{blur_tag}\"\n",
    "                rf\"\\fscx120\\fscy120\\t(0,120,\\fscx95\\fscy95)\\t(120,{in_ms},\\fscx100\\fscy100){bord_anim}}}\")\n",
    "    if name == \"slide_up\":\n",
    "        return rf\"{{\\an5\\move({cx},{cy+60},{cx},{cy},0,{in_ms}){bord_tag0}{blur_tag}}}\"\n",
    "    if name == \"slide_down\":\n",
    "        return rf\"{{\\an5\\move({cx},{cy-60},{cx},{cy},0,{in_ms}){bord_tag0}{blur_tag}}}\"\n",
    "    if name == \"slide_left\":\n",
    "        return rf\"{{\\an5\\move({cx-140},{cy},{cx},{cy},0,{in_ms}){bord_tag0}{blur_tag}}}\"\n",
    "    if name == \"slide_right\":\n",
    "        return rf\"{{\\an5\\move({cx+140},{cy},{cx},{cy},0,{in_ms}){bord_tag0}{blur_tag}}}\"\n",
    "    if name == \"rotate\":\n",
    "        return rf\"{{\\an5\\pos({cx},{cy}){bord_tag0}{blur_tag}\\frz-12\\t(0,{in_ms},\\frz0)}}\"\n",
    "    if name == \"inflate\":\n",
    "        return rf\"{{\\an5\\pos({cx},{cy}){bord_tag0}{blur_tag}\\fscx80\\fscy80\\t(0,{in_ms},\\fscx100\\fscy100){bord_anim}}}\"\n",
    "    if name == \"inflate_soft\":\n",
    "        return (rf\"{{\\an5\\pos({cx},{cy}){bord_tag0}{blur_tag}\\fscx80\\fscy80\\alpha&H20&\\blur2\"\n",
    "                rf\"\\t(0,{in_ms},\\fscx100\\fscy100\\alpha&H00&\\blur0){bord_anim}}}\")\n",
    "    return rf\"{{\\an5\\pos({cx},{cy}){bord_tag0}{blur_tag}}}\"\n",
    "\n",
    "# ---------- Group words into captions ----------\n",
    "def clean_token(s: str) -> str:\n",
    "    s = (s or \"\").strip()\n",
    "    s = re.sub(r\"^\\s+|\\s+$\", \"\", s)\n",
    "    return re.sub(r\"^\\W+|\\W+$\", \"\", s)\n",
    "\n",
    "def group_words_to_captions(words,\n",
    "                            max_words=1,\n",
    "                            max_chars=None,\n",
    "                            max_gap_s=0.6):\n",
    "    lines, cur = [], []\n",
    "    last_end = None\n",
    "    for w in words:\n",
    "        token = clean_token(w[\"text\"])\n",
    "        if not token:\n",
    "            continue\n",
    "        gap = (w[\"start\"] - last_end) if last_end is not None else 0.0\n",
    "\n",
    "        join_len = len((\" \".join([x[\"text\"] for x in cur] + [token])).strip())\n",
    "        need_new = False\n",
    "        if last_end is not None and gap > max_gap_s:\n",
    "            need_new = True\n",
    "        if cur and len(cur) >= max_words:\n",
    "            need_new = True\n",
    "        if (not need_new) and (max_chars is not None) and (join_len > max_chars):\n",
    "            need_new = True\n",
    "\n",
    "        if need_new and cur:\n",
    "            lines.append(cur)\n",
    "            cur = []\n",
    "\n",
    "        cur.append({\"start\": float(w[\"start\"]), \"end\": float(w[\"end\"]), \"text\": token})\n",
    "        last_end = float(w[\"end\"])\n",
    "\n",
    "    if cur:\n",
    "        lines.append(cur)\n",
    "    return lines\n",
    "\n",
    "def build_center_caption_events(lines,\n",
    "                                play_w: int, play_h: int,\n",
    "                                uppercase=True,\n",
    "                                min_caption=0.30,\n",
    "                                cut_ahead=0.00,\n",
    "                                tail_hold=1.20,\n",
    "                                anim=\"none\",\n",
    "                                in_ms=220,\n",
    "                                out_ms=100,\n",
    "                                border_px=12.0,\n",
    "                                stabilize_outline=True,\n",
    "                                blur_px=0.0):\n",
    "    cx = int(round(play_w / 2))\n",
    "    cy = int(round(play_h / 2))\n",
    "    events = []\n",
    "    n = len(lines)\n",
    "    for i, ln in enumerate(lines):\n",
    "        t0 = float(ln[0][\"start\"])\n",
    "        natural_end = float(ln[-1][\"end\"])\n",
    "        t1 = max(natural_end, t0 + min_caption)\n",
    "\n",
    "        if i + 1 < n:\n",
    "            next_start = float(lines[i+1][0][\"start\"])\n",
    "            gap_after = max(0.0, next_start - natural_end - cut_ahead)\n",
    "            t1 = min(max(t1, natural_end + min(tail_hold, gap_after)), next_start - cut_ahead)\n",
    "        else:\n",
    "            t1 = max(natural_end + tail_hold, t0 + min_caption)\n",
    "\n",
    "        if t1 <= t0:\n",
    "            t1 = t0 + 0.05\n",
    "\n",
    "        text = \" \".join([w[\"text\"] for w in ln]).strip()\n",
    "        if uppercase:\n",
    "            text = text.upper()\n",
    "\n",
    "        ov = anim_tag(cx, cy, anim, in_ms, out_ms, border_px, stabilize_outline, blur_px)\n",
    "        events.append(f\"Dialogue: 0,{_fmt_time(t0)},{_fmt_time(t1)},Beast,,0,0,0,,{ov}{text}\")\n",
    "    return events\n",
    "\n",
    "# ---------- NEW: resolve an intro image from a file OR folder -------------\n",
    "def resolve_intro_image(src: Path | None) -> Path | None:\n",
    "    if not src:\n",
    "        return None\n",
    "    src = Path(src).expanduser()\n",
    "    if not src.exists():\n",
    "        return None\n",
    "    if src.is_file():\n",
    "        return src\n",
    "    # folder: pick first image\n",
    "    for ext in (\"*.png\",\"*.jpg\",\"*.jpeg\",\"*.webp\"):\n",
    "        files = sorted(src.glob(ext))\n",
    "        if files:\n",
    "            return files[0]\n",
    "    return None\n",
    "\n",
    "# ---------- MAIN: captions + optional reddit intro overlay ----------------\n",
    "def beta_captions(INPUT_VIDEO: str | Path,\n",
    "                  intro_card_src: Path | None = INTRO_CARD_SRC,\n",
    "                  intro_enabled: bool = INTRO_ENABLED,\n",
    "                  intro_secs: float = INTRO_SECS,\n",
    "                  intro_fade: float = INTRO_FADE,\n",
    "                  intro_scale: float = INTRO_SCALE,\n",
    "                  intro_crop_bottom: float = INTRO_CROP_BOTTOM,\n",
    "                  intro_offset_x: int = INTRO_OFFSET_X,\n",
    "                  intro_offset_y: int = INTRO_OFFSET_Y) -> str:\n",
    "\n",
    "    # ---------- 1) Transcribe ----------\n",
    "    video_path = Path(INPUT_VIDEO).expanduser().resolve()\n",
    "    assert video_path.exists(), f\"Video not found: {video_path}\"\n",
    "    print(\"[info] video:\", video_path)\n",
    "\n",
    "    PLAY_W, PLAY_H = probe_resolution(video_path) if AUTO_PLAYRES else (1920, 1080)\n",
    "    if CENTER_X is None or CENTER_Y is None:\n",
    "        cx, cy = PLAY_W // 2, PLAY_H // 2\n",
    "    else:\n",
    "        cx, cy = CENTER_X, CENTER_Y\n",
    "    print(f\"[info] PlayRes set to: {PLAY_W}x{PLAY_H} | Center=({cx},{cy})\")\n",
    "\n",
    "    print(\"[info] loading Whisper model …\")\n",
    "    model = load_whisper_auto(MODEL_NAME)\n",
    "\n",
    "    print(\"[info] transcribing (word timestamps) …\")\n",
    "    segments, _ = model.transcribe(str(video_path), vad_filter=True, word_timestamps=True)\n",
    "\n",
    "    words = []\n",
    "    for seg in segments:\n",
    "        if seg.words:\n",
    "            for w in seg.words:\n",
    "                tok = (w.word or \"\").strip()\n",
    "                if tok:\n",
    "                    words.append({\"start\": float(w.start), \"end\": float(w.end), \"text\": tok})\n",
    "\n",
    "    print(f\"[info] words captured: {len(words)}\")\n",
    "\n",
    "    # ---------- 2) Build ASS ----------\n",
    "    font_file, FONT_NAME = pick_custom_font(CUSTOM_FONT_DIR)\n",
    "    ASS_HEADER = ASS_HEADER_TMPL.format(\n",
    "        play_w=PLAY_W, play_h=PLAY_H, font=FONT_NAME, size=FONT_SIZE,\n",
    "        border=_fmt_float(BORDER_PX), shadow=_fmt_float(SHADOW_PX)\n",
    "    )\n",
    "\n",
    "    caption_lines = group_words_to_captions(\n",
    "        words,\n",
    "        max_words=MAX_WORDS_PER_CAP,\n",
    "        max_chars=MAX_CHARS_PER_CAP,\n",
    "        max_gap_s=MAX_GAP_SEC\n",
    "    )\n",
    "    print(f\"[info] caption groups built: {len(caption_lines)} \"\n",
    "          f\"(max_words={MAX_WORDS_PER_CAP}, max_chars={MAX_CHARS_PER_CAP}, max_gap_s={MAX_GAP_SEC})\")\n",
    "\n",
    "    ass_events = build_center_caption_events(\n",
    "        caption_lines,\n",
    "        play_w=PLAY_W, play_h=PLAY_H,\n",
    "        uppercase=UPPERCASE,\n",
    "        min_caption=MIN_CAPTION_SEC,\n",
    "        cut_ahead=CUT_AHEAD_SEC,\n",
    "        tail_hold=TAIL_HOLD_SEC,\n",
    "        anim=ANIM,\n",
    "        in_ms=ANIM_IN_MS,\n",
    "        out_ms=ANIM_OUT_MS,\n",
    "        border_px=BORDER_PX,\n",
    "        stabilize_outline=STABILIZE_OUTLINE,\n",
    "        blur_px=BLUR_PX\n",
    "    )\n",
    "    ass_text = ASS_HEADER + \"\\n\".join(ass_events)\n",
    "\n",
    "    # ---------- 3) Decide output path ----------\n",
    "    out_dir = ensure_dir(Path(OUTPUT_DIR))\n",
    "    safe_stem = sanitize_stem(video_path.stem)\n",
    "    ts = timestamp()\n",
    "    out_name = FILENAME_TEMPLATE.format(stem=safe_stem, ts=ts, anim=ANIM)\n",
    "    out_video = (out_dir / out_name).resolve()\n",
    "    out_tmp = out_video.with_suffix(\".tmp.mp4\")\n",
    "\n",
    "    print(\"[info] OUTPUT_DIR:\", out_dir)\n",
    "    print(\"[info] Output file:\", out_video)\n",
    "\n",
    "    # ---------- 4) FFmpeg (write temp .ass and burn) ----------\n",
    "    if not shutil.which(\"ffmpeg\"):\n",
    "        raise SystemExit(\"FFmpeg not found on PATH. Install it and rerun.\")\n",
    "\n",
    "    fontsdir_arg = f\":fontsdir={CUSTOM_FONT_DIR.as_posix()}\"\n",
    "\n",
    "    tmp_path = None\n",
    "    try:\n",
    "        # write ASS to temp file\n",
    "        with tempfile.NamedTemporaryFile(\"w\", suffix=\".ass\", delete=False, encoding=\"utf-8\") as tmp:\n",
    "            tmp.write(ass_text)\n",
    "            tmp.flush()\n",
    "            tmp_path = Path(tmp.name)\n",
    "\n",
    "        vcodec = \"h264_videotoolbox\" if platform.system() == \"Darwin\" else \"libx264\"\n",
    "\n",
    "        # Try to resolve an intro image (file or from folder)\n",
    "        intro_img = resolve_intro_image(intro_card_src) if intro_enabled else None\n",
    "        if intro_img:\n",
    "            print(f\"[info] intro card: {intro_img}\")\n",
    "\n",
    "        if intro_img and intro_secs > 0:\n",
    "            # --- subtitles chain for the base video ---\n",
    "            if YUV444_RENDER:\n",
    "                base_chain = f\"format=yuv444p,ass={tmp_path.as_posix()}{fontsdir_arg}\"\n",
    "            else:\n",
    "                base_chain = f\"ass={tmp_path.as_posix()}{fontsdir_arg}\"\n",
    "\n",
    "            # Safe clamps\n",
    "            fade_d     = max(0.0, min(float(intro_fade), float(intro_secs)))\n",
    "            crop_keep  = max(0.0, min(1.0, 1.0 - float(intro_crop_bottom)))\n",
    "            scale_frac = max(0.05, min(2.0, float(intro_scale)))\n",
    "\n",
    "            # Compute target card width in pixels (even number for H.264)\n",
    "            scaled_w = int(round(PLAY_W * scale_frac))\n",
    "            if scaled_w % 2:\n",
    "                scaled_w -= 1\n",
    "            if scaled_w < 2:\n",
    "                scaled_w = 2  # safety\n",
    "\n",
    "            # Filter graph:\n",
    "            # [0:v] -> subtitles -> [base]\n",
    "            # [1:v] -> crop -> scale to scaled_w -> fade alpha -> [cardf]\n",
    "            # [base][cardf] overlay centered for first intro_secs -> [vout]\n",
    "            fc = (\n",
    "                f\"[0:v]{base_chain}[base];\"\n",
    "                f\"[1:v]format=rgba,crop=iw:ih*{crop_keep}:0:0[cardc];\"\n",
    "                f\"[cardc]scale={scaled_w}:-1[cards];\"\n",
    "                f\"[cards]fade=t=out:st={intro_secs - fade_d}:d={fade_d}:alpha=1[cardf];\"\n",
    "                f\"[base][cardf]overlay=\"\n",
    "                f\"x=(main_w-overlay_w)/2+{int(intro_offset_x)}:\"\n",
    "                f\"y=(main_h-overlay_h)/2+{int(intro_offset_y)}:\"\n",
    "                f\"enable=between(t,0,{intro_secs})\"\n",
    "                f\"[v];\"\n",
    "                f\"[v]format=yuv420p[vout]\"\n",
    "            )\n",
    "\n",
    "            cmd = [\n",
    "                \"ffmpeg\", \"-y\",\n",
    "                \"-i\", str(video_path),\n",
    "                \"-loop\", \"1\", \"-t\", f\"{intro_secs + 0.5}\", \"-i\", str(intro_img),\n",
    "                \"-filter_complex\", fc,\n",
    "                \"-map\", \"[vout]\", \"-map\", \"0:a?\",\n",
    "                \"-c:v\", vcodec, \"-preset\", \"veryfast\", \"-crf\", \"18\",\n",
    "                \"-c:a\", \"copy\",\n",
    "                \"-movflags\", \"+faststart\",\n",
    "                str(out_tmp)\n",
    "            ]\n",
    "\n",
    "        else:\n",
    "            # --- subtitles only with -vf ---\n",
    "            if YUV444_RENDER:\n",
    "                vf_arg = f\"format=yuv444p,ass={tmp_path.as_posix()}{fontsdir_arg},format=yuv420p\"\n",
    "            else:\n",
    "                vf_arg = f\"ass={tmp_path.as_posix()}{fontsdir_arg}\"\n",
    "\n",
    "            cmd = [\n",
    "                \"ffmpeg\", \"-y\",\n",
    "                \"-i\", str(video_path),\n",
    "                \"-vf\", vf_arg,\n",
    "                \"-c:v\", vcodec, \"-preset\", \"veryfast\", \"-crf\", \"18\",\n",
    "                \"-c:a\", \"copy\",\n",
    "                \"-movflags\", \"+faststart\",\n",
    "                str(out_tmp)\n",
    "            ]\n",
    "\n",
    "        print(\"[info] ffmpeg cmd:\", \" \".join(cmd))\n",
    "        run = subprocess.run(cmd, check=False, text=True, capture_output=True)\n",
    "        if run.returncode != 0:\n",
    "            print(run.stderr)\n",
    "            raise RuntimeError(f\"ffmpeg failed (code {run.returncode})\")\n",
    "\n",
    "        out_tmp.replace(out_video)\n",
    "        print(\"[done] saved:\", out_video)\n",
    "\n",
    "    finally:\n",
    "        if tmp_path and tmp_path.exists():\n",
    "            try:\n",
    "                tmp_path.unlink()\n",
    "            except Exception as e:\n",
    "                print(f\"[warn] could not delete temp ASS: {e}\")\n",
    "        if out_tmp.exists():\n",
    "            try:\n",
    "                out_tmp.unlink()\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    if not out_video.exists():\n",
    "        raise FileNotFoundError(f\"Expected output not found: {out_video}\")\n",
    "    return out_video.as_posix()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ceadaec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] video: /Users/marcus/Downloads/reddit1_filmora_captioned/tester12345.mp4\n",
      "[info] PlayRes set to: 1080x1920 | Center=(540,960)\n",
      "[info] loading Whisper model …\n",
      "[info] trying compute_type=float16 …\n",
      "[skip] Requested float16 compute type, but the target device or backend do not support efficient float16 computation.\n",
      "[info] trying compute_type=int8 …\n",
      "[info] transcribing (word timestamps) …\n",
      "[info] words captured: 22\n",
      "[font] Using file: /Users/marcus/Documents/mrbeast_caps/fonts/KOMIKAX_.ttf\n",
      "[font] Font family set to: Komika Axis\n",
      "[info] caption groups built: 22 (max_words=1, max_chars=None, max_gap_s=1.2)\n",
      "[info] OUTPUT_DIR: /Users/marcus/Downloads/reddit1_filmora_captioned\n",
      "[info] Output file: /Users/marcus/Downloads/reddit1_filmora_captioned/exported_20250906_020900.mp4\n",
      "[info] intro card: /Users/marcus/Downloads/Thumb_shorts_white.png\n",
      "[info] ffmpeg cmd: ffmpeg -y -i /Users/marcus/Downloads/reddit1_filmora_captioned/tester12345.mp4 -loop 1 -t 3.5 -i /Users/marcus/Downloads/Thumb_shorts_white.png -filter_complex [0:v]format=yuv444p,ass=/var/folders/n2/rstg0c3j7hv2shgc8szmsj2r0000gp/T/tmpsd_b4_ri.ass:fontsdir=/Users/marcus/Documents/mrbeast_caps/fonts[base];[1:v]format=rgba,crop=iw:ih*0.88:0:0[cardc];[cardc]scale=994:-1[cards];[cards]fade=t=out:st=2.7:d=0.3:alpha=1[cardf];[base][cardf]overlay=x=(main_w-overlay_w)/2+0:y=(main_h-overlay_h)/2+0:enable=between(t,0,3.0)[v];[v]format=yuv420p[vout] -map [vout] -map 0:a? -c:v h264_videotoolbox -preset veryfast -crf 18 -c:a copy -movflags +faststart /Users/marcus/Downloads/reddit1_filmora_captioned/exported_20250906_020900.tmp.mp4\n",
      "ffmpeg version 8.0 Copyright (c) 2000-2025 the FFmpeg developers\n",
      "  built with Apple clang version 17.0.0 (clang-1700.0.13.3)\n",
      "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/8.0_1 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n",
      "  libavutil      60.  8.100 / 60.  8.100\n",
      "  libavcodec     62. 11.100 / 62. 11.100\n",
      "  libavformat    62.  3.100 / 62.  3.100\n",
      "  libavdevice    62.  1.100 / 62.  1.100\n",
      "  libavfilter    11.  4.100 / 11.  4.100\n",
      "  libswscale      9.  1.100 /  9.  1.100\n",
      "  libswresample   6.  1.100 /  6.  1.100\n",
      "[AVFilterGraph @ 0x15a904cf0] No such filter: '0'\n",
      "Error : Filter not found\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "ffmpeg failed (code 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Or override per-call:\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mbeta_captions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/Users/marcus/Downloads/reddit1_filmora_captioned/tester12345.mp4\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mintro_card_src\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/Users/marcus/Downloads/Thumb_shorts_white.png\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mintro_secs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mintro_fade\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mintro_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.92\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mintro_crop_bottom\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.12\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mintro_offset_x\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mintro_offset_y\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\n\u001b[32m     11\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 472\u001b[39m, in \u001b[36mbeta_captions\u001b[39m\u001b[34m(INPUT_VIDEO, intro_card_src, intro_enabled, intro_secs, intro_fade, intro_scale, intro_crop_bottom, intro_offset_x, intro_offset_y)\u001b[39m\n\u001b[32m    470\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m run.returncode != \u001b[32m0\u001b[39m:\n\u001b[32m    471\u001b[39m     \u001b[38;5;28mprint\u001b[39m(run.stderr)\n\u001b[32m--> \u001b[39m\u001b[32m472\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mffmpeg failed (code \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun.returncode\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    474\u001b[39m out_tmp.replace(out_video)\n\u001b[32m    475\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m[done] saved:\u001b[39m\u001b[33m\"\u001b[39m, out_video)\n",
      "\u001b[31mRuntimeError\u001b[39m: ffmpeg failed (code 8)"
     ]
    }
   ],
   "source": [
    "# Or override per-call:\n",
    "beta_captions(\n",
    "    \"/Users/marcus/Downloads/reddit1_filmora_captioned/tester12345.mp4\",\n",
    "    intro_card_src=Path(\"/Users/marcus/Downloads/Thumb_shorts_white.png\"),\n",
    "    intro_secs=3.0,\n",
    "    intro_fade=0.3,\n",
    "    intro_scale=0.92,\n",
    "    intro_crop_bottom=0.12,\n",
    "    intro_offset_x=0,\n",
    "    intro_offset_y=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8009561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CONFIG ==============================================================\n",
    "\n",
    "from pathlib import Path\n",
    "import tempfile\n",
    "\n",
    "# Where to save the rendered video:\n",
    "OUTPUT_DIR = Path.home() / \"Downloads\" / \"reddit1_filmora_captioned\"\n",
    "\n",
    "# Filename pattern (placeholders: {stem}=input filename stem, {ts}=timestamp, {anim}=ANIM)\n",
    "FILENAME_TEMPLATE = \"exported_{ts}.mp4\"\n",
    "\n",
    "MODEL_NAME        = \"small.en\"       # tiny/base/small/medium/large-v3; *.en faster for English\n",
    "\n",
    "# Caption look\n",
    "FONT_SIZE         = 210\n",
    "UPPERCASE         = True\n",
    "\n",
    "# Outline controls\n",
    "BORDER_PX         = 12.0\n",
    "SHADOW_PX         = 2.0\n",
    "BLUR_PX           = 0.0\n",
    "STABILIZE_OUTLINE = True\n",
    "\n",
    "# Timing hyperparams\n",
    "MIN_CAPTION_SEC   = 0.30\n",
    "CUT_AHEAD_SEC     = 0.00\n",
    "TAIL_HOLD_SEC     = 1.20\n",
    "\n",
    "# Grouping hyperparams\n",
    "MAX_WORDS_PER_CAP = 1\n",
    "MAX_CHARS_PER_CAP = None\n",
    "MAX_GAP_SEC       = 1.20\n",
    "\n",
    "# Animation\n",
    "ANIM              = \"inflate\"\n",
    "ANIM_IN_MS        = 20000\n",
    "ANIM_OUT_MS       = 50\n",
    "\n",
    "# Fonts\n",
    "CUSTOM_FONT_DIR   = Path.home() / \"Documents\" / \"mrbeast_caps\" / \"fonts\"\n",
    "\n",
    "# Rendering safety\n",
    "AUTO_PLAYRES      = True             # match ASS PlayRes to actual video resolution\n",
    "YUV444_RENDER     = True             # render subs in 4:4:4 to stabilize edges, then downsample\n",
    "\n",
    "# --- NEW: Reddit intro card overlay --------------------------------------\n",
    "INTRO_CARD_SRC     = Path(\"/Users/marcus/Downloads/Thumb_shorts_white\")   # file OR folder; None disables\n",
    "INTRO_ENABLED      = True\n",
    "INTRO_SECS         = 3.0\n",
    "INTRO_FADE         = 0.30\n",
    "INTRO_SCALE        = 0.92\n",
    "INTRO_CROP_BOTTOM  = 0.12\n",
    "INTRO_OFFSET_X     = 0\n",
    "INTRO_OFFSET_Y     = 0\n",
    "INTRO_ROUND_PX     = 40   \n",
    "# ========================================================================\n",
    "\n",
    "import os, subprocess, shutil, platform, re, sys\n",
    "from datetime import timedelta\n",
    "from faster_whisper import WhisperModel\n",
    "from datetime import datetime\n",
    "\n",
    "def timestamp(fmt: str = \"%Y%m%d_%H%M%S\") -> str:\n",
    "    return datetime.now().strftime(fmt)\n",
    "\n",
    "def sanitize_stem(stem: str) -> str:\n",
    "    return re.sub(r'[^A-Za-z0-9_.-]+', '_', stem).strip('_')\n",
    "\n",
    "def ensure_dir(p: Path) -> Path:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "    return p\n",
    "\n",
    "# ---------- probe video resolution ----------\n",
    "def probe_resolution(video_path: Path) -> tuple[int, int]:\n",
    "    cmd = [\n",
    "        \"ffprobe\",\"-v\",\"error\",\"-select_streams\",\"v:0\",\n",
    "        \"-show_entries\",\"stream=width,height\",\"-of\",\"csv=s=x:p=0\", str(video_path)\n",
    "    ]\n",
    "    try:\n",
    "        out = subprocess.check_output(cmd, text=True).strip()\n",
    "        w, h = map(int, out.split(\"x\"))\n",
    "        print(f\"[info] probed resolution: {w}x{h}\")\n",
    "        return w, h\n",
    "    except Exception:\n",
    "        print(\"[warn] ffprobe failed, falling back to 1920x1080\")\n",
    "        return 1920, 1080\n",
    "\n",
    "CENTER_X, CENTER_Y = None, None\n",
    "\n",
    "# ---------- load Whisper ----------\n",
    "import platform as _pf\n",
    "def load_whisper_auto(model_name: str):\n",
    "    osname = _pf.system()\n",
    "    candidates = ([\"float16\", \"int8\", \"float32\"] if osname == \"Darwin\"\n",
    "                  else [\"int8_float16\", \"int8\", \"float16\", \"float32\"])\n",
    "    last = None\n",
    "    for ct in candidates:\n",
    "        try:\n",
    "            print(f\"[info] trying compute_type={ct} …\")\n",
    "            return WhisperModel(model_name, compute_type=ct, device=\"auto\")\n",
    "        except ValueError as e:\n",
    "            print(f\"[skip] {e}\")\n",
    "            last = e\n",
    "    raise last\n",
    "\n",
    "# ---------- font ----------\n",
    "def pick_custom_font(font_dir: Path):\n",
    "    font_dir.mkdir(parents=True, exist_ok=True)\n",
    "    candidates = list(font_dir.glob(\"*.ttf\")) + list(font_dir.glob(\"*.otf\"))\n",
    "    if not candidates:\n",
    "        print(\"\\n[FONT SETUP REQUIRED]\")\n",
    "        print(\"1) Download any .ttf or .otf font.\")\n",
    "        print(f\"2) Place it here: {font_dir}\")\n",
    "        print(\"3) Re-run.\")\n",
    "        raise SystemExit(\"[exit] No font found yet.\")\n",
    "    font_file = candidates[0]\n",
    "    family = None\n",
    "    try:\n",
    "        from fontTools.ttLib import TTFont\n",
    "        tt = TTFont(font_file)\n",
    "        names = {n.nameID: n.toUnicode() for n in tt[\"name\"].names if n.toUnicode()}\n",
    "        family = names.get(1) or names.get(4)\n",
    "    except Exception:\n",
    "        family = font_file.stem\n",
    "    print(\"[font] Using file:\", font_file)\n",
    "    print(\"[font] Font family set to:\", family)\n",
    "    return font_file, family\n",
    "\n",
    "# ---------- ASS header ----------\n",
    "ASS_HEADER_TMPL = \"\"\"[Script Info]\n",
    "ScriptType: v4.00+\n",
    "PlayResX: {play_w}\n",
    "PlayResY: {play_h}\n",
    "ScaledBorderAndShadow: yes\n",
    "WrapStyle: 2\n",
    "\n",
    "[V4+ Styles]\n",
    "Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding\n",
    "; White text (Primary), THICK black outline, subtle shadow for separation.\n",
    "Style: Beast,{font},{size},&H00FFFFFF,&H00FFFFFF,&H00000000,&H64000000,-1,0,0,0,100,100,0,0,1,{border},{shadow},5,60,60,60,1\n",
    "\n",
    "[Events]\n",
    "Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text\n",
    "\"\"\"\n",
    "\n",
    "def _fmt_time(t: float) -> str:\n",
    "    td = timedelta(seconds=max(0.0, t))\n",
    "    cs = int(round(td.total_seconds() * 100))\n",
    "    h, rem = divmod(cs, 360000)\n",
    "    m, rem = divmod(rem, 6000)\n",
    "    s, cs = divmod(rem, 100)\n",
    "    return f\"{h}:{m:02d}:{s:02d}.{cs:02d}\"\n",
    "\n",
    "def _scale_spec_for_anim(name: str):\n",
    "    name = (name or \"none\").lower()\n",
    "    if name in (\"inflate\", \"inflate_soft\", \"pop\"):\n",
    "        return 80, 100\n",
    "    if name == \"zoom\":\n",
    "        return 60, 100\n",
    "    return 100, 100\n",
    "\n",
    "def _fmt_float(x: float) -> str:\n",
    "    return f\"{x:.2f}\".rstrip(\"0\").rstrip(\".\")\n",
    "\n",
    "def anim_tag(cx: int, cy: int, name: str, in_ms: int, out_ms: int,\n",
    "             border_px: float, stabilize_outline: bool, blur_px: float) -> str:\n",
    "    cx, cy = int(round(cx)), int(round(cy))\n",
    "    s0, s1 = _scale_spec_for_anim(name)\n",
    "    if stabilize_outline and (s0 != s1):\n",
    "        bord0 = border_px * (s0 / 100.0)\n",
    "        bord1 = border_px * (s1 / 100.0)\n",
    "        bord_tag0 = rf\"\\bord{_fmt_float(bord0)}\"\n",
    "        bord_anim = rf\"\\t(0,{in_ms},\\bord{_fmt_float(bord1)})\"\n",
    "    else:\n",
    "        bord_tag0 = rf\"\\bord{_fmt_float(border_px)}\"\n",
    "        bord_anim = \"\"\n",
    "    blur_tag = (rf\"\\blur{_fmt_float(blur_px)}\" if blur_px and blur_px > 0 else \"\")\n",
    "    name = (name or \"none\").lower()\n",
    "    if name == \"none\":\n",
    "        return rf\"{{\\an5\\pos({cx},{cy}){bord_tag0}{blur_tag}}}\"\n",
    "    if name == \"fade\":\n",
    "        return rf\"{{\\an5\\pos({cx},{cy}){bord_tag0}{blur_tag}\\fad({in_ms},{out_ms})}}\"\n",
    "    if name == \"pop\":\n",
    "        return rf\"{{\\an5\\pos({cx},{cy}){bord_tag0}{blur_tag}\\fscx80\\fscy80\\t(0,{in_ms},\\fscx100\\fscy100){bord_anim}}}\"\n",
    "    if name == \"zoom\":\n",
    "        return rf\"{{\\an5\\pos({cx},{cy}){bord_tag0}{blur_tag}\\fscx60\\fscy60\\t(0,{in_ms},\\fscx100\\fscy100){bord_anim}}}\"\n",
    "    if name == \"bounce\":\n",
    "        return (rf\"{{\\an5\\move({cx},{cy-40},{cx},{cy},0,{in_ms}){bord_tag0}{blur_tag}\"\n",
    "                rf\"\\fscx120\\fscy120\\t(0,120,\\fscx95\\fscy95)\\t(120,{in_ms},\\fscx100\\fscy100){bord_anim}}}\")\n",
    "    if name == \"slide_up\":\n",
    "        return rf\"{{\\an5\\move({cx},{cy+60},{cx},{cy},0,{in_ms}){bord_tag0}{blur_tag}}}\"\n",
    "    if name == \"slide_down\":\n",
    "        return rf\"{{\\an5\\move({cx},{cy-60},{cx},{cy},0,{in_ms}){bord_tag0}{blur_tag}}}\"\n",
    "    if name == \"slide_left\":\n",
    "        return rf\"{{\\an5\\move({cx-140},{cy},{cx},{cy},0,{in_ms}){bord_tag0}{blur_tag}}}\"\n",
    "    if name == \"slide_right\":\n",
    "        return rf\"{{\\an5\\move({cx+140},{cy},{cx},{cy},0,{in_ms}){bord_tag0}{blur_tag}}}\"\n",
    "    if name == \"rotate\":\n",
    "        return rf\"{{\\an5\\pos({cx},{cy}){bord_tag0}{blur_tag}\\frz-12\\t(0,{in_ms},\\frz0)}}\"\n",
    "    if name == \"inflate\":\n",
    "        return rf\"{{\\an5\\pos({cx},{cy}){bord_tag0}{blur_tag}\\fscx80\\fscy80\\t(0,{in_ms},\\fscx100\\fscy100){bord_anim}}}\"\n",
    "    if name == \"inflate_soft\":\n",
    "        return (rf\"{{\\an5\\pos({cx},{cy}){bord_tag0}{blur_tag}\\fscx80\\fscy80\\alpha&H20&\\blur2\"\n",
    "                rf\"\\t(0,{in_ms},\\fscx100\\fscy100\\alpha&H00&\\blur0){bord_anim}}}\")\n",
    "    return rf\"{{\\an5\\pos({cx},{cy}){bord_tag0}{blur_tag}}}\"\n",
    "\n",
    "# ---------- Group words into captions ----------\n",
    "def clean_token(s: str) -> str:\n",
    "    s = (s or \"\").strip()\n",
    "    s = re.sub(r\"^\\s+|\\s+$\", \"\", s)\n",
    "    return re.sub(r\"^\\W+|\\W+$\", \"\", s)\n",
    "\n",
    "def group_words_to_captions(words,\n",
    "                            max_words=1,\n",
    "                            max_chars=None,\n",
    "                            max_gap_s=0.6):\n",
    "    lines, cur = [], []\n",
    "    last_end = None\n",
    "    for w in words:\n",
    "        token = clean_token(w[\"text\"])\n",
    "        if not token:\n",
    "            continue\n",
    "        gap = (w[\"start\"] - last_end) if last_end is not None else 0.0\n",
    "\n",
    "        join_len = len((\" \".join([x[\"text\"] for x in cur] + [token])).strip())\n",
    "        need_new = False\n",
    "        if last_end is not None and gap > max_gap_s:\n",
    "            need_new = True\n",
    "        if cur and len(cur) >= max_words:\n",
    "            need_new = True\n",
    "        if (not need_new) and (max_chars is not None) and (join_len > max_chars):\n",
    "            need_new = True\n",
    "\n",
    "        if need_new and cur:\n",
    "            lines.append(cur)\n",
    "            cur = []\n",
    "\n",
    "        cur.append({\"start\": float(w[\"start\"]), \"end\": float(w[\"end\"]), \"text\": token})\n",
    "        last_end = float(w[\"end\"])\n",
    "\n",
    "    if cur:\n",
    "        lines.append(cur)\n",
    "    return lines\n",
    "\n",
    "def build_center_caption_events(lines,\n",
    "                                play_w: int, play_h: int,\n",
    "                                uppercase=True,\n",
    "                                min_caption=0.30,\n",
    "                                cut_ahead=0.00,\n",
    "                                tail_hold=1.20,\n",
    "                                anim=\"none\",\n",
    "                                in_ms=220,\n",
    "                                out_ms=100,\n",
    "                                border_px=12.0,\n",
    "                                stabilize_outline=True,\n",
    "                                blur_px=0.0):\n",
    "    cx = int(round(play_w / 2))\n",
    "    cy = int(round(play_h / 2))\n",
    "    events = []\n",
    "    n = len(lines)\n",
    "    for i, ln in enumerate(lines):\n",
    "        t0 = float(ln[0][\"start\"])\n",
    "        natural_end = float(ln[-1][\"end\"])\n",
    "        t1 = max(natural_end, t0 + min_caption)\n",
    "\n",
    "        if i + 1 < n:\n",
    "            next_start = float(lines[i+1][0][\"start\"])\n",
    "            gap_after = max(0.0, next_start - natural_end - cut_ahead)\n",
    "            t1 = min(max(t1, natural_end + min(tail_hold, gap_after)), next_start - cut_ahead)\n",
    "        else:\n",
    "            t1 = max(natural_end + tail_hold, t0 + min_caption)\n",
    "\n",
    "        if t1 <= t0:\n",
    "            t1 = t0 + 0.05\n",
    "\n",
    "        text = \" \".join([w[\"text\"] for w in ln]).strip()\n",
    "        if uppercase:\n",
    "            text = text.upper()\n",
    "\n",
    "        ov = anim_tag(cx, cy, anim, in_ms, out_ms, border_px, stabilize_outline, blur_px)\n",
    "        events.append(f\"Dialogue: 0,{_fmt_time(t0)},{_fmt_time(t1)},Beast,,0,0,0,,{ov}{text}\")\n",
    "    return events\n",
    "\n",
    "# ---------- resolve an intro image (file OR folder) -------------\n",
    "def resolve_intro_image(src: Path | None) -> Path | None:\n",
    "    if not src:\n",
    "        print(\"[debug] resolve_intro_image: src=None\")\n",
    "        return None\n",
    "    src = Path(src).expanduser()\n",
    "    print(f\"[debug] resolve_intro_image: candidate='{src}' exists={src.exists()} is_dir={src.is_dir()}\")\n",
    "    if src.exists():\n",
    "        if src.is_file():\n",
    "            return src\n",
    "        # folder: pick first image\n",
    "        allowed = {\".png\",\".jpg\",\".jpeg\",\".webp\",\".bmp\"}\n",
    "        imgs = [f for f in sorted(src.iterdir()) if f.is_file() and f.suffix.lower() in allowed]\n",
    "        return imgs[0] if imgs else None\n",
    "    return None\n",
    "\n",
    "# ---------- MAIN ----------------------------------------------------------\n",
    "def beta_captions(INPUT_VIDEO: str | Path,\n",
    "                  intro_card_src: Path | None = INTRO_CARD_SRC,\n",
    "                  intro_enabled: bool = INTRO_ENABLED,\n",
    "                  intro_secs: float = INTRO_SECS,\n",
    "                  intro_fade: float = INTRO_FADE,\n",
    "                  intro_scale: float = INTRO_SCALE,\n",
    "                  intro_crop_bottom: float = INTRO_CROP_BOTTOM,\n",
    "                  intro_offset_x: int = INTRO_OFFSET_X,\n",
    "                  intro_offset_y: int = INTRO_OFFSET_Y,\n",
    "                  intro_round_px: int = INTRO_ROUND_PX) -> str:\n",
    "\n",
    "    video_path = Path(INPUT_VIDEO).expanduser().resolve()\n",
    "    assert video_path.exists(), f\"Video not found: {video_path}\"\n",
    "    print(\"[info] video:\", video_path)\n",
    "\n",
    "    PLAY_W, PLAY_H = probe_resolution(video_path) if AUTO_PLAYRES else (1920, 1080)\n",
    "    if CENTER_X is None or CENTER_Y is None:\n",
    "        cx, cy = PLAY_W // 2, PLAY_H // 2\n",
    "    else:\n",
    "        cx, cy = CENTER_X, CENTER_Y\n",
    "    print(f\"[info] PlayRes set to: {PLAY_W}x{PLAY_H} | Center=({cx},{cy})\")\n",
    "\n",
    "    print(\"[info] loading Whisper model …\")\n",
    "    model = load_whisper_auto(MODEL_NAME)\n",
    "\n",
    "    print(\"[info] transcribing (word timestamps) …\")\n",
    "    segments, _ = model.transcribe(str(video_path), vad_filter=True, word_timestamps=True)\n",
    "\n",
    "    words = []\n",
    "    for seg in segments:\n",
    "        if seg.words:\n",
    "            for w in seg.words:\n",
    "                tok = (w.word or \"\").strip()\n",
    "                if tok:\n",
    "                    words.append({\"start\": float(w.start), \"end\": float(w.end), \"text\": tok})\n",
    "\n",
    "    print(f\"[info] words captured: {len(words)}\")\n",
    "\n",
    "    # ---------- Build ASS ----------\n",
    "    _, FONT_NAME = pick_custom_font(CUSTOM_FONT_DIR)\n",
    "    ASS_HEADER = ASS_HEADER_TMPL.format(\n",
    "        play_w=PLAY_W, play_h=PLAY_H, font=FONT_NAME, size=FONT_SIZE,\n",
    "        border=_fmt_float(BORDER_PX), shadow=_fmt_float(SHADOW_PX)\n",
    "    )\n",
    "\n",
    "    caption_lines = group_words_to_captions(\n",
    "        words,\n",
    "        max_words=MAX_WORDS_PER_CAP,\n",
    "        max_chars=MAX_CHARS_PER_CAP,\n",
    "        max_gap_s=MAX_GAP_SEC\n",
    "    )\n",
    "    print(f\"[info] caption groups built: {len(caption_lines)} \"\n",
    "          f\"(max_words={MAX_WORDS_PER_CAP}, max_chars={MAX_CHARS_PER_CAP}, max_gap_s={MAX_GAP_SEC})\")\n",
    "\n",
    "    ass_events = build_center_caption_events(\n",
    "        caption_lines,\n",
    "        play_w=PLAY_W, play_h=PLAY_H,\n",
    "        uppercase=UPPERCASE,\n",
    "        min_caption=MIN_CAPTION_SEC,\n",
    "        cut_ahead=CUT_AHEAD_SEC,\n",
    "        tail_hold=TAIL_HOLD_SEC,\n",
    "        anim=ANIM,\n",
    "        in_ms=ANIM_IN_MS,\n",
    "        out_ms=ANIM_OUT_MS,\n",
    "        border_px=BORDER_PX,\n",
    "        stabilize_outline=STABILIZE_OUTLINE,\n",
    "        blur_px=BLUR_PX\n",
    "    )\n",
    "    ass_text = ASS_HEADER + \"\\n\".join(ass_events)\n",
    "\n",
    "    # ---------- Output path ----------\n",
    "    out_dir = ensure_dir(Path(OUTPUT_DIR))\n",
    "    ts = timestamp()\n",
    "    out_name = FILENAME_TEMPLATE.format(stem=sanitize_stem(video_path.stem), ts=ts, anim=ANIM)\n",
    "    out_video = (out_dir / out_name).resolve()\n",
    "    out_tmp = out_video.with_suffix(\".tmp.mp4\")\n",
    "    print(\"[info] OUTPUT_DIR:\", out_dir)\n",
    "    print(\"[info] Output file:\", out_video)\n",
    "\n",
    "    if not shutil.which(\"ffmpeg\"):\n",
    "        raise SystemExit(\"FFmpeg not found on PATH. Install it and rerun.\")\n",
    "\n",
    "    fontsdir_arg = f\":fontsdir={CUSTOM_FONT_DIR.as_posix()}\"\n",
    "\n",
    "    tmp_path = None\n",
    "    try:\n",
    "        # write ASS to temp file\n",
    "        with tempfile.NamedTemporaryFile(\"w\", suffix=\".ass\", delete=False, encoding=\"utf-8\") as tmp:\n",
    "            tmp.write(ass_text)\n",
    "            tmp.flush()\n",
    "            tmp_path = Path(tmp.name)\n",
    "\n",
    "        vcodec = \"h264_videotoolbox\" if platform.system() == \"Darwin\" else \"libx264\"\n",
    "\n",
    "        intro_img = resolve_intro_image(intro_card_src) if intro_enabled else None\n",
    "        print(f\"[debug] intro_enabled={intro_enabled} intro_secs={intro_secs} intro_fade={intro_fade}\")\n",
    "        print(f\"[debug] resolved intro image: {intro_img}\")\n",
    "\n",
    "        if intro_img and intro_secs > 0:\n",
    "            # subtitles chain for base video\n",
    "            base_chain = (f\"format=yuv444p,ass={tmp_path.as_posix()}{fontsdir_arg}\"\n",
    "                        if YUV444_RENDER else\n",
    "                        f\"ass={tmp_path.as_posix()}{fontsdir_arg}\")\n",
    "\n",
    "            fade_d     = max(0.0, min(float(intro_fade), float(intro_secs)))\n",
    "            crop_keep  = max(0.0, min(1.0, 1.0 - float(intro_crop_bottom)))\n",
    "            scale_frac = max(0.05, min(2.0, float(intro_scale)))\n",
    "            scaled_w   = int(round(PLAY_W * scale_frac))\n",
    "            if scaled_w % 2: scaled_w -= 1\n",
    "            if scaled_w < 2: scaled_w = 2\n",
    "\n",
    "            enable_expr = f\"between(t\\\\,0\\\\,{intro_secs})\"  # escape commas\n",
    "\n",
    "            round_px = max(0, int(intro_round_px))\n",
    "            print(f\"[debug] overlay params: crop_keep={crop_keep} scale_frac={scale_frac} \"\n",
    "                f\"scaled_w={scaled_w} fade_d={fade_d} offsets=({intro_offset_x},{intro_offset_y}) \"\n",
    "                f\"round_px={round_px}\")\n",
    "\n",
    "            # Build the card-processing chain; if rounding requested, compute an alpha mask via geq()\n",
    "            if round_px > 0:\n",
    "                # alpha expression: 255 inside rounded-rect, 0 outside\n",
    "                aexpr = (\n",
    "                    f\"if(lte(hypot(\"\n",
    "                    f\"if(lt(X,{round_px}),{round_px}-X,if(lt(W-X,{round_px}),{round_px}-(W-X),0)),\"\n",
    "                    f\"if(lt(Y,{round_px}),{round_px}-Y,if(lt(H-Y,{round_px}),{round_px}-(H-Y),0))\"\n",
    "                    f\"),{round_px}),255,0)\"\n",
    "                )\n",
    "                card_chain = (\n",
    "                    f\"[cardc]scale={scaled_w}:-1[card_s];\"\n",
    "                    f\"[card_s]format=rgba,\"\n",
    "                    f\"geq=r='r(X,Y)':g='g(X,Y)':b='b(X,Y)':a='{aexpr}'[card_r];\"\n",
    "                    f\"[card_r]fade=t=out:st={intro_secs - fade_d}:d={fade_d}:alpha=1[cardf];\"\n",
    "                )\n",
    "            else:\n",
    "                card_chain = (\n",
    "                    f\"[cardc]scale={scaled_w}:-1[cards];\"\n",
    "                    f\"[cards]fade=t=out:st={intro_secs - fade_d}:d={fade_d}:alpha=1[cardf];\"\n",
    "                )\n",
    "\n",
    "            fc = (\n",
    "                f\"[0:v]{base_chain}[base];\"\n",
    "                f\"[1:v]format=rgba,crop=iw:ih*{crop_keep}:0:0[cardc];\"\n",
    "                f\"{card_chain}\"\n",
    "                f\"[base][cardf]overlay=\"\n",
    "                f\"x=(main_w-overlay_w)/2+{int(intro_offset_x)}:\"\n",
    "                f\"y=(main_h-overlay_h)/2+{int(intro_offset_y)}:\"\n",
    "                f\"enable='{enable_expr}'[v];\"\n",
    "                f\"[v]format=yuv420p[vout]\"\n",
    "            )\n",
    "            print(\"[debug] filter_complex >>>\\n\" + fc + \"\\n<<< end filter_complex\")\n",
    "\n",
    "\n",
    "            cmd = [\n",
    "                \"ffmpeg\",\"-y\",\"-hide_banner\",\"-loglevel\",\"info\",\n",
    "                \"-i\", str(video_path),\n",
    "                \"-loop\",\"1\",\"-t\", f\"{intro_secs + 0.5}\",\"-i\", str(intro_img),\n",
    "                \"-filter_complex\", fc,\n",
    "                \"-map\",\"[vout]\",\"-map\",\"0:a?\",\n",
    "                \"-c:v\", vcodec, \"-preset\",\"veryfast\",\"-crf\",\"18\",\n",
    "                \"-c:a\",\"copy\",\n",
    "                \"-movflags\",\"+faststart\",\n",
    "                str(out_tmp)\n",
    "            ]\n",
    "        else:\n",
    "            vf_arg = (f\"format=yuv444p,ass={tmp_path.as_posix()}{fontsdir_arg},format=yuv420p\"\n",
    "                      if YUV444_RENDER else\n",
    "                      f\"ass={tmp_path.as_posix()}{fontsdir_arg}\")\n",
    "            cmd = [\n",
    "                \"ffmpeg\",\"-y\",\"-hide_banner\",\"-loglevel\",\"info\",\n",
    "                \"-i\", str(video_path),\n",
    "                \"-vf\", vf_arg,\n",
    "                \"-c:v\", vcodec, \"-preset\",\"veryfast\",\"-crf\",\"18\",\n",
    "                \"-c:a\",\"copy\",\n",
    "                \"-movflags\",\"+faststart\",\n",
    "                str(out_tmp)\n",
    "            ]\n",
    "\n",
    "        print(\"[info] ffmpeg cmd:\", \" \".join(cmd))\n",
    "        run = subprocess.run(cmd, check=False, text=True, capture_output=True)\n",
    "        if run.returncode != 0:\n",
    "            # show head/tail to diagnose\n",
    "            err = run.stderr or \"\"\n",
    "            head = \"\\n\".join(err.splitlines()[:20])\n",
    "            tail = \"\\n\".join(err.splitlines()[-20:])\n",
    "            print(\"\\n[ffmpeg stderr — head]\\n\" + head + \"\\n\")\n",
    "            print(\"[ffmpeg stderr — tail]\\n\" + tail + \"\\n\")\n",
    "            print(\"[ffmpeg stderr — end]\")\n",
    "            raise RuntimeError(f\"ffmpeg failed (code {run.returncode})\")\n",
    "\n",
    "        out_tmp.replace(out_video)\n",
    "        print(\"[done] saved:\", out_video)\n",
    "\n",
    "    finally:\n",
    "        if tmp_path and tmp_path.exists():\n",
    "            try: tmp_path.unlink()\n",
    "            except Exception as e: print(f\"[warn] could not delete temp ASS: {e}\")\n",
    "        if out_tmp.exists():\n",
    "            try: out_tmp.unlink()\n",
    "            except Exception: pass\n",
    "\n",
    "    if not out_video.exists():\n",
    "        raise FileNotFoundError(f\"Expected output not found: {out_video}\")\n",
    "    return out_video.as_posix()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c9e9305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] video: /Users/marcus/Downloads/reddit1_filmora_captioned/tester12345.mp4\n",
      "[info] probed resolution: 1080x1920\n",
      "[info] PlayRes set to: 1080x1920 | Center=(540,960)\n",
      "[info] loading Whisper model …\n",
      "[info] trying compute_type=float16 …\n",
      "[skip] Requested float16 compute type, but the target device or backend do not support efficient float16 computation.\n",
      "[info] trying compute_type=int8 …\n",
      "[info] transcribing (word timestamps) …\n",
      "[info] words captured: 22\n",
      "[font] Using file: /Users/marcus/Documents/mrbeast_caps/fonts/KOMIKAX_.ttf\n",
      "[font] Font family set to: Komika Axis\n",
      "[info] caption groups built: 22 (max_words=1, max_chars=None, max_gap_s=1.2)\n",
      "[info] OUTPUT_DIR: /Users/marcus/Downloads/reddit1_filmora_captioned\n",
      "[info] Output file: /Users/marcus/Downloads/reddit1_filmora_captioned/exported_20250906_023447.mp4\n",
      "[debug] resolve_intro_image: candidate='/Users/marcus/Downloads/Shorts_thumbv2w.png' exists=True is_dir=False\n",
      "[debug] intro_enabled=True intro_secs=4.0 intro_fade=0.1\n",
      "[debug] resolved intro image: /Users/marcus/Downloads/Shorts_thumbv2w.png\n",
      "[debug] overlay params: crop_keep=0.75 scale_frac=0.8 scaled_w=864 fade_d=0.1 offsets=(0,0) round_px=45\n",
      "[debug] filter_complex >>>\n",
      "[0:v]format=yuv444p,ass=/var/folders/n2/rstg0c3j7hv2shgc8szmsj2r0000gp/T/tmp20vx1ojz.ass:fontsdir=/Users/marcus/Documents/mrbeast_caps/fonts[base];[1:v]format=rgba,crop=iw:ih*0.75:0:0[cardc];[cardc]scale=864:-1[card_s];[card_s]format=rgba,geq=r='r(X,Y)':g='g(X,Y)':b='b(X,Y)':a='if(lte(hypot(if(lt(X,45),45-X,if(lt(W-X,45),45-(W-X),0)),if(lt(Y,45),45-Y,if(lt(H-Y,45),45-(H-Y),0))),45),255,0)'[card_r];[card_r]fade=t=out:st=3.9:d=0.1:alpha=1[cardf];[base][cardf]overlay=x=(main_w-overlay_w)/2+0:y=(main_h-overlay_h)/2+0:enable='between(t\\,0\\,4.0)'[v];[v]format=yuv420p[vout]\n",
      "<<< end filter_complex\n",
      "[info] ffmpeg cmd: ffmpeg -y -hide_banner -loglevel info -i /Users/marcus/Downloads/reddit1_filmora_captioned/tester12345.mp4 -loop 1 -t 4.5 -i /Users/marcus/Downloads/Shorts_thumbv2w.png -filter_complex [0:v]format=yuv444p,ass=/var/folders/n2/rstg0c3j7hv2shgc8szmsj2r0000gp/T/tmp20vx1ojz.ass:fontsdir=/Users/marcus/Documents/mrbeast_caps/fonts[base];[1:v]format=rgba,crop=iw:ih*0.75:0:0[cardc];[cardc]scale=864:-1[card_s];[card_s]format=rgba,geq=r='r(X,Y)':g='g(X,Y)':b='b(X,Y)':a='if(lte(hypot(if(lt(X,45),45-X,if(lt(W-X,45),45-(W-X),0)),if(lt(Y,45),45-Y,if(lt(H-Y,45),45-(H-Y),0))),45),255,0)'[card_r];[card_r]fade=t=out:st=3.9:d=0.1:alpha=1[cardf];[base][cardf]overlay=x=(main_w-overlay_w)/2+0:y=(main_h-overlay_h)/2+0:enable='between(t\\,0\\,4.0)'[v];[v]format=yuv420p[vout] -map [vout] -map 0:a? -c:v h264_videotoolbox -preset veryfast -crf 18 -c:a copy -movflags +faststart /Users/marcus/Downloads/reddit1_filmora_captioned/exported_20250906_023447.tmp.mp4\n",
      "[done] saved: /Users/marcus/Downloads/reddit1_filmora_captioned/exported_20250906_023447.mp4\n"
     ]
    }
   ],
   "source": [
    "# Or override per-call:\n",
    "pathing = beta_captions(\n",
    "    \"/Users/marcus/Downloads/reddit1_filmora_captioned/tester12345.mp4\",\n",
    "    intro_card_src=Path(\"/Users/marcus/Downloads/Shorts_thumbv2w.png\"),\n",
    "    intro_secs=4.0,\n",
    "    intro_fade=0.1,\n",
    "    intro_scale=0.80,\n",
    "    intro_crop_bottom=0.25,\n",
    "    intro_offset_x=0,\n",
    "    intro_offset_y=0,\n",
    "    intro_round_px=45\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa9eab35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/marcus/Downloads/reddit1_filmora_captioned/exported_20250906_023447.mp4'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pathing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "76232c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "def _timestamp(fmt=\"%Y%m%d_%H%M%S\") -> str:\n",
    "    return datetime.now().strftime(fmt)\n",
    "\n",
    "def _ensure_dir(p: Path) -> Path:\n",
    "    p = Path(p)\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "    return p\n",
    "\n",
    "def _find_arial_path() -> Path | None:\n",
    "    \"\"\"Try common system paths for 'Arial.ttf' (macOS/Windows).\"\"\"\n",
    "    candidates = [\n",
    "        # macOS\n",
    "        \"/System/Library/Fonts/Supplemental/Arial.ttf\",\n",
    "        \"/System/Library/Fonts/Arial.ttf\",\n",
    "        \"/Library/Fonts/Arial.ttf\",\n",
    "        # Windows\n",
    "        \"C:/Windows/Fonts/arial.ttf\",\n",
    "        \"C:/Windows/Fonts/Arial.ttf\",\n",
    "    ]\n",
    "    for c in candidates:\n",
    "        p = Path(c)\n",
    "        if p.exists():\n",
    "            return p\n",
    "    return None\n",
    "\n",
    "def render_sentence_on_thumbnail(\n",
    "    image_path: str | Path,\n",
    "    sentence: str,\n",
    "    box: tuple[int, int, int, int],           # (x, y, w, h) in pixels\n",
    "    out_dir: str | Path = \"/Users/marcus/Downloads/shorts_thumbnails_storage\",\n",
    "    # Font controls\n",
    "    font_path: str | Path | None = None,       # None => auto-resolve Arial\n",
    "    min_font: int = 16,\n",
    "    max_font: int = 420,\n",
    "    line_spacing: float = 1.08,                # line height multiplier\n",
    "    letter_spacing_px: int = 0,                # NEW: tracking in pixels\n",
    "    # Color & effects\n",
    "    fill=(255, 255, 255),                      # text fill color\n",
    "    stroke_fill=(0, 0, 0),                     # outline color\n",
    "    stroke_ratio: float = 0.08,                # outline thickness as % of font size\n",
    "    bold_strength_px: int = 0,                 # NEW: thicken fill by Npx (draw extra passes)\n",
    "    padding_px: int = 12,                      # inner padding inside the box\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Draw `sentence` into `box=(x,y,w,h)` on `image_path`, choosing the largest uniform font size\n",
    "    that fits both width and height (with wrapping). Supports letter spacing and adjustable fill\n",
    "    boldness (thickness). Saves a PNG to `out_dir` and returns its path.\n",
    "    \"\"\"\n",
    "\n",
    "    image_path = Path(image_path)\n",
    "    out_dir = _ensure_dir(Path(out_dir))\n",
    "    assert image_path.exists(), f\"Image not found: {image_path}\"\n",
    "\n",
    "    # Resolve font\n",
    "    if font_path is None:\n",
    "        arial = _find_arial_path()\n",
    "        if not arial:\n",
    "            raise FileNotFoundError(\n",
    "                \"Arial.ttf not found on this system. Pass a valid `font_path` to a .ttf file.\"\n",
    "            )\n",
    "        font_path = arial\n",
    "    font_path = Path(font_path)\n",
    "    assert font_path.exists(), f\"Font not found: {font_path}\"\n",
    "\n",
    "    # Load image + drawer\n",
    "    img = Image.open(image_path).convert(\"RGBA\")\n",
    "    draw = ImageDraw.Draw(img)\n",
    "\n",
    "    x, y, bw, bh = box\n",
    "    inner_w = max(1, bw - 2 * padding_px)\n",
    "    inner_h = max(1, bh - 2 * padding_px)\n",
    "\n",
    "    # --- measurement helpers (respect letter spacing) ---------------------\n",
    "    def char_width(ch: str, font: ImageFont.FreeTypeFont, stroke_w: int) -> int:\n",
    "        bbox = draw.textbbox((0, 0), ch, font=font, stroke_width=stroke_w)\n",
    "        return bbox[2] - bbox[0]\n",
    "\n",
    "    def line_width(line: str, font: ImageFont.FreeTypeFont, stroke_w: int) -> int:\n",
    "        if not line:\n",
    "            return 0\n",
    "        total = 0\n",
    "        for i, ch in enumerate(line):\n",
    "            total += char_width(ch, font, stroke_w)\n",
    "            if i < len(line) - 1:\n",
    "                total += max(0, letter_spacing_px)\n",
    "        return total\n",
    "\n",
    "    def wrap_lines(font: ImageFont.FreeTypeFont, text: str, max_w: int, stroke_w: int) -> list[str]:\n",
    "        \"\"\"Greedy word wrap using width with tracking.\"\"\"\n",
    "        words = text.split()\n",
    "        lines: list[str] = []\n",
    "        cur = \"\"\n",
    "        for w in words:\n",
    "            attempt = (cur + \" \" + w).strip() if cur else w\n",
    "            if line_width(attempt, font, stroke_w) <= max_w:\n",
    "                cur = attempt\n",
    "            else:\n",
    "                if cur:\n",
    "                    lines.append(cur)\n",
    "                cur = w\n",
    "        if cur:\n",
    "            lines.append(cur)\n",
    "        return lines\n",
    "\n",
    "    def block_size(font: ImageFont.FreeTypeFont, lines: list[str], stroke_w: int) -> tuple[int, int]:\n",
    "        \"\"\"Return (max_width, total_height) for wrapped lines with spacing and stroke.\"\"\"\n",
    "        max_w_px, total_h = 0, 0\n",
    "        ascent, descent = font.getmetrics()\n",
    "        # Add a tiny headroom for stroke top/bottom\n",
    "        base_line_h = ascent + descent + stroke_w\n",
    "        line_h = int(round(base_line_h * line_spacing))\n",
    "        for ln in lines:\n",
    "            w_px = line_width(ln, font, stroke_w)\n",
    "            max_w_px = max(max_w_px, w_px)\n",
    "            total_h += line_h\n",
    "        # a little extra breathing space\n",
    "        total_h += max(1, stroke_w)\n",
    "        return max_w_px, total_h\n",
    "\n",
    "    # --- search best font size -------------------------------------------\n",
    "    best = None\n",
    "    lo, hi = int(min_font), int(max_font)\n",
    "    while lo <= hi:\n",
    "        mid = (lo + hi) // 2\n",
    "        font_mid = ImageFont.truetype(str(font_path), mid)\n",
    "        stroke_w = max(0, int(round(mid * stroke_ratio)))\n",
    "        lines = wrap_lines(font_mid, sentence, inner_w, stroke_w)\n",
    "        w_px, h_px = block_size(font_mid, lines, stroke_w)\n",
    "        if w_px <= inner_w and h_px <= inner_h:\n",
    "            best = (mid, stroke_w, lines)\n",
    "            lo = mid + 1   # try bigger\n",
    "        else:\n",
    "            hi = mid - 1   # too big\n",
    "\n",
    "    if best is None:\n",
    "        # fallback: smallest size\n",
    "        size = int(min_font)\n",
    "        lines = wrap_lines(ImageFont.truetype(str(font_path), size), sentence, inner_w, 0)\n",
    "        stroke_w = max(0, int(round(size * stroke_ratio)))\n",
    "        fnt = ImageFont.truetype(str(font_path), size)\n",
    "    else:\n",
    "        size, stroke_w, lines = best\n",
    "        fnt = ImageFont.truetype(str(font_path), size)\n",
    "\n",
    "    # --- compute vertical centering ---------------------------------------\n",
    "    ascent, descent = fnt.getmetrics()\n",
    "    base_line_h = ascent + descent + stroke_w\n",
    "    line_h = int(round(base_line_h * line_spacing))\n",
    "    total_h = len(lines) * line_h + max(1, stroke_w)\n",
    "    start_y = y + padding_px + (inner_h - total_h) // 2\n",
    "    center_x = x + bw // 2\n",
    "\n",
    "    # --- draw with tracking + optional bold fill --------------------------\n",
    "    def draw_line(ln: str, top_y: int):\n",
    "        # center horizontally using measured width with tracking\n",
    "        ln_w = line_width(ln, fnt, stroke_w)\n",
    "        left_x = int(center_x - ln_w / 2)\n",
    "\n",
    "        # helper: draw one pass of the whole line (char-by-char)\n",
    "        def _draw_pass(dx: int, dy: int, use_stroke: bool, color):\n",
    "            cx = left_x + dx\n",
    "            for i, ch in enumerate(ln):\n",
    "                draw.text((cx, top_y + dy), ch, font=fnt, fill=color,\n",
    "                          stroke_width=stroke_w if use_stroke else 0,\n",
    "                          stroke_fill=stroke_fill if use_stroke else None)\n",
    "                cx += char_width(ch, fnt, stroke_w) + max(0, letter_spacing_px)\n",
    "\n",
    "        # Thicken fill first (no stroke) by drawing nearby offsets\n",
    "        r = max(0, int(bold_strength_px))\n",
    "        if r > 0:\n",
    "            offsets = {\n",
    "                ( r, 0), (-r, 0), (0,  r), (0, -r),\n",
    "                ( r,  r), ( r, -r), (-r,  r), (-r, -r),\n",
    "            }\n",
    "            for dx, dy in offsets:\n",
    "                _draw_pass(dx, dy, use_stroke=False, color=fill)\n",
    "\n",
    "        # Main pass: with outline for crisp edges\n",
    "        _draw_pass(0, 0, use_stroke=True, color=fill)\n",
    "\n",
    "    cur_y = start_y\n",
    "    for ln in lines:\n",
    "        draw_line(ln, cur_y)\n",
    "        cur_y += line_h\n",
    "\n",
    "    out_path = out_dir / f\"thumb_{_timestamp()}.png\"\n",
    "    img.save(out_path, format=\"PNG\", optimize=True)\n",
    "    return str(out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "89264401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /Users/marcus/Downloads/shorts_thumbnails_storage/thumb_20250906_030330.png\n"
     ]
    }
   ],
   "source": [
    "out_png = render_sentence_on_thumbnail(\n",
    "    image_path=\"/Users/marcus/Downloads/Shorts_thumbv2w.png\",\n",
    "    sentence=\"Doctors lied about my brother’s condition after he went into a coma.\",\n",
    "    box=(40, 60, 1080, 500),  # (x, y, w, h) tuned for your template\n",
    "    out_dir=\"/Users/marcus/Downloads/shorts_thumbnails_storage\",\n",
    "    font_path=None,                 # None => auto-detect Arial; or pass a .ttf path explicitly\n",
    "    min_font=28,\n",
    "    max_font=28,\n",
    "    line_spacing=1.06,\n",
    "    letter_spacing_px=0.0,            # NEW: tweak tracking\n",
    "    bold_strength_px=1,             # NEW: thicken fill by ~1px (set 0 to disable)\n",
    "    fill=(255, 255, 255),\n",
    "    stroke_fill=(0, 0, 0),\n",
    "    stroke_ratio=1.00,              # outline ≈ 9% of size\n",
    "    padding_px=0,\n",
    ")\n",
    "print(\"Saved:\", out_png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "656cbc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "def _ts(fmt=\"%Y%m%d_%H%M%S\"): \n",
    "    return datetime.now().strftime(fmt)\n",
    "\n",
    "def _ensure_dir(p: str | Path) -> Path:\n",
    "    p = Path(p); p.mkdir(parents=True, exist_ok=True); return p\n",
    "\n",
    "def _find_arial() -> Path | None:\n",
    "    # Common macOS / Windows locations\n",
    "    for p in [\n",
    "        \"/System/Library/Fonts/Supplemental/Arial.ttf\",\n",
    "        \"/System/Library/Fonts/Arial.ttf\",\n",
    "        \"/Library/Fonts/Arial.ttf\",\n",
    "        \"C:/Windows/Fonts/arial.ttf\",\n",
    "        \"C:/Windows/Fonts/Arial.ttf\",\n",
    "    ]:\n",
    "        if Path(p).exists(): return Path(p)\n",
    "    return None\n",
    "\n",
    "def render_black_topleft(\n",
    "    image_path: str | Path,\n",
    "    text: str,\n",
    "    box: tuple[int, int, int, int],      # (x, y, w, h) area to fill\n",
    "    out_dir: str | Path = \"/Users/marcus/Downloads/shorts_thumbnails_storage\",\n",
    "    font_size: int = 160,                 # target size; will shrink-to-fit\n",
    "    min_font: int = 24,                   # shrink floor\n",
    "    line_spacing: float = 1.08,           # line height multiplier\n",
    "    letter_spacing_px: int = 0,           # tracking between all characters\n",
    "    bold_px: int = 0,                     # thickness (0=normal). Uses stroke to “embolden”\n",
    "    padding_px: int = 8,                  # inner padding inside the box\n",
    "    font_path: str | Path | None = None,  # None => auto-find Arial\n",
    "    color=(0, 0, 0),                      # solid black\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Draws plain black Arial from the TOP-LEFT of `box`, word-wrapped.\n",
    "    Uses `font_size` but shrinks if needed to fit width & height.\n",
    "    Boldness is simulated via stroke_width (thickness in pixels).\n",
    "    Returns the saved PNG path.\n",
    "    \"\"\"\n",
    "    image_path = Path(image_path); assert image_path.exists(), f\"Image not found: {image_path}\"\n",
    "    out_dir = _ensure_dir(out_dir)\n",
    "\n",
    "    if font_path is None:\n",
    "        font_path = _find_arial()\n",
    "        if not font_path:\n",
    "            raise FileNotFoundError(\"Arial.ttf not found. Pass `font_path` to a valid .ttf.\")\n",
    "    font_path = Path(font_path); assert font_path.exists(), f\"Font not found: {font_path}\"\n",
    "\n",
    "    img = Image.open(image_path).convert(\"RGBA\")\n",
    "    draw = ImageDraw.Draw(img)\n",
    "\n",
    "    x, y, bw, bh = box\n",
    "    max_w = max(1, bw - 2 * padding_px)\n",
    "    max_h = max(1, bh - 2 * padding_px)\n",
    "\n",
    "    # ---------- measurement helpers (respect stroke & letter spacing) ----------\n",
    "    def char_size(ch: str, fnt: ImageFont.FreeTypeFont) -> tuple[int, int]:\n",
    "        b = draw.textbbox((0, 0), ch, font=fnt, stroke_width=bold_px)\n",
    "        return b[2] - b[0], b[3] - b[1]\n",
    "\n",
    "    def string_width(s: str, fnt: ImageFont.FreeTypeFont) -> int:\n",
    "        if not s: return 0\n",
    "        w = 0\n",
    "        for i, ch in enumerate(s):\n",
    "            cw, _ = char_size(ch, fnt)\n",
    "            w += cw\n",
    "            if i < len(s) - 1:\n",
    "                w += max(0, letter_spacing_px)\n",
    "        return w\n",
    "\n",
    "    def single_line_height(fnt: ImageFont.FreeTypeFont) -> int:\n",
    "        # bbox includes stroke; multiply by line_spacing\n",
    "        b = draw.textbbox((0, 0), \"Hg\", font=fnt, stroke_width=bold_px)\n",
    "        raw = max(1, b[3] - b[1])\n",
    "        return int(round(raw * line_spacing))\n",
    "\n",
    "    def wrap_words(fnt: ImageFont.FreeTypeFont, s: str, maxw: int) -> list[str]:\n",
    "        words = s.split()\n",
    "        lines, cur = [], \"\"\n",
    "        for w in words:\n",
    "            cand = (cur + \" \" + w).strip() if cur else w\n",
    "            if string_width(cand, fnt) <= maxw:\n",
    "                cur = cand\n",
    "            else:\n",
    "                if cur: lines.append(cur)\n",
    "                cur = w   # assume no single-word outliers per your guarantee\n",
    "        if cur: lines.append(cur)\n",
    "        return lines\n",
    "\n",
    "    def block_dims(fnt: ImageFont.FreeTypeFont, lines: list[str]) -> tuple[int, int]:\n",
    "        lh = single_line_height(fnt)\n",
    "        H = len(lines) * lh\n",
    "        W = 0\n",
    "        for ln in lines:\n",
    "            W = max(W, string_width(ln, fnt))\n",
    "        return W, H\n",
    "\n",
    "    # ---------- fit loop ----------\n",
    "    size = max(min_font, int(font_size))\n",
    "    fnt = ImageFont.truetype(str(font_path), size)\n",
    "    lines = wrap_words(fnt, text, max_w)\n",
    "    W, H = block_dims(fnt, lines)\n",
    "\n",
    "    while (W > max_w or H > max_h) and size > min_font:\n",
    "        size -= 2\n",
    "        fnt = ImageFont.truetype(str(font_path), size)\n",
    "        lines = wrap_words(fnt, text, max_w)\n",
    "        W, H = block_dims(fnt, lines)\n",
    "\n",
    "    # ---------- draw top-left (no centering) ----------\n",
    "    tx = x + padding_px\n",
    "    ty = y + padding_px\n",
    "    lh = single_line_height(fnt)\n",
    "\n",
    "    for ln in lines:\n",
    "        cx = tx\n",
    "        for i, ch in enumerate(ln):\n",
    "            draw.text(\n",
    "                (cx, ty),\n",
    "                ch,\n",
    "                font=fnt,\n",
    "                fill=color,\n",
    "                stroke_width=max(0, bold_px),\n",
    "                stroke_fill=color,   # stroke same color = thicker glyph\n",
    "            )\n",
    "            cw, _ = char_size(ch, fnt)\n",
    "            cx += cw + max(0, letter_spacing_px)\n",
    "        ty += lh\n",
    "\n",
    "    out_path = out_dir / f\"thumb_black_tl_{_ts()}.png\"\n",
    "    img.save(out_path, \"PNG\", optimize=True)\n",
    "    return str(out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cff991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: /Users/marcus/Downloads/shorts_thumbnails_storage/thumb_black_tl_20250906_032007.png\n"
     ]
    }
   ],
   "source": [
    "saved_path = render_black_topleft(\n",
    "    image_path=\"/Users/marcus/Downloads/Shorts_thumbv2w.png\",\n",
    "    text=\"Have you ever accidentally saved a life? I like playing clash royale and reaching\",\n",
    "    box=(40, 235, 1200, 200),              # (x, y, w, h) — the white card area\n",
    "    out_dir=\"/Users/marcus/Downloads/shorts_thumbnails_storage\",\n",
    "    font_size=70,                         # target “X size”\n",
    "    min_font=48,\n",
    "    line_spacing=1.42,\n",
    "    letter_spacing_px=0,                   # normal spacing\n",
    "    bold_px=1.6,                             # thickness (0=normal, try 2–4 for bold)\n",
    "    # font_path=None,                      # leave None to auto-find Arial\n",
    ")\n",
    "print(\"Saved to:\", saved_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "03383f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "def _ts(fmt=\"%Y%m%d_%H%M%S\"): \n",
    "    return datetime.now().strftime(fmt)\n",
    "\n",
    "def _ensure_dir(p: str | Path) -> Path:\n",
    "    p = Path(p); p.mkdir(parents=True, exist_ok=True); return p\n",
    "\n",
    "def _find_arial() -> Path | None:\n",
    "    # Common macOS / Windows locations\n",
    "    for p in [\n",
    "        \"/System/Library/Fonts/Supplemental/Arial.ttf\",\n",
    "        \"/System/Library/Fonts/Arial.ttf\",\n",
    "        \"/Library/Fonts/Arial.ttf\",\n",
    "        \"C:/Windows/Fonts/arial.ttf\",\n",
    "        \"C:/Windows/Fonts/Arial.ttf\",\n",
    "    ]:\n",
    "        if Path(p).exists(): return Path(p)\n",
    "    return None\n",
    "\n",
    "def render_black_topleft(\n",
    "    image_path: str | Path,\n",
    "    text: str,\n",
    "    box: tuple[int, int, int, int],      # (x, y, w, h)\n",
    "    out_dir: str | Path = \"/Users/marcus/Downloads/shorts_thumbnails_storage\",\n",
    "    font_size: int = 160,                 # will shrink-to-fit\n",
    "    min_font: int = 24,\n",
    "    line_spacing: float = 1.08,\n",
    "    letter_spacing_px: int = 0,           # can be negative (tighten letters)\n",
    "    space_extra_px: int = 0,              # added to spaces between words\n",
    "    bold_px: int = 0,                     # thickness via stroke\n",
    "    padding_px: int = 8,\n",
    "    font_path: str | Path | None = None,  # None => auto-find Arial\n",
    "    color=(0, 0, 0),\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Draws plain black Arial from the TOP-LEFT of `box`, word-wrapped.\n",
    "    `letter_spacing_px` applies between letters inside words (can be negative).\n",
    "    `space_extra_px` adds extra pixels to spaces (word gaps).\n",
    "    Returns saved PNG path.\n",
    "    \"\"\"\n",
    "    image_path = Path(image_path); assert image_path.exists(), f\"Image not found: {image_path}\"\n",
    "    out_dir = _ensure_dir(out_dir)\n",
    "\n",
    "    if font_path is None:\n",
    "        font_path = _find_arial()\n",
    "        if not font_path:\n",
    "            raise FileNotFoundError(\"Arial.ttf not found. Pass `font_path` to a valid .ttf.\")\n",
    "    font_path = Path(font_path); assert font_path.exists(), f\"Font not found: {font_path}\"\n",
    "\n",
    "    img = Image.open(image_path).convert(\"RGBA\")\n",
    "    draw = ImageDraw.Draw(img)\n",
    "\n",
    "    x, y, bw, bh = box\n",
    "    max_w = max(1, bw - 2 * padding_px)\n",
    "    max_h = max(1, bh - 2 * padding_px)\n",
    "\n",
    "    # ---------- measurement helpers ----------\n",
    "    def char_bbox(s: str, fnt: ImageFont.FreeTypeFont):\n",
    "        return draw.textbbox((0, 0), s, font=fnt, stroke_width=bold_px)\n",
    "\n",
    "    def char_size(ch: str, fnt: ImageFont.FreeTypeFont) -> tuple[int, int]:\n",
    "        b = char_bbox(ch, fnt)\n",
    "        return b[2] - b[0], b[3] - b[1]\n",
    "\n",
    "    def string_width(s: str, fnt: ImageFont.FreeTypeFont) -> int:\n",
    "        if not s: return 0\n",
    "        w = 0\n",
    "        for i, ch in enumerate(s):\n",
    "            cw, _ = char_size(ch, fnt)\n",
    "            w += cw\n",
    "            if i < len(s) - 1:\n",
    "                nxt = s[i + 1]\n",
    "                if ch == ' ':\n",
    "                    # widen spaces themselves\n",
    "                    w += max(0, space_extra_px)\n",
    "                else:\n",
    "                    # letter spacing only if the next thing isn't a space\n",
    "                    if nxt != ' ':\n",
    "                        w += letter_spacing_px\n",
    "        return max(0, w)\n",
    "\n",
    "    def line_height(fnt: ImageFont.FreeTypeFont) -> int:\n",
    "        b = char_bbox(\"Hg\", fnt)\n",
    "        raw = max(1, b[3] - b[1])\n",
    "        return int(round(raw * line_spacing))\n",
    "\n",
    "    def wrap_words(fnt: ImageFont.FreeTypeFont, s: str, maxw: int) -> list[str]:\n",
    "        words = s.split()\n",
    "        lines, cur = [], \"\"\n",
    "        for w in words:\n",
    "            cand = (cur + \" \" + w).strip() if cur else w\n",
    "            if string_width(cand, fnt) <= maxw:\n",
    "                cur = cand\n",
    "            else:\n",
    "                if cur: lines.append(cur)\n",
    "                cur = w\n",
    "        if cur: lines.append(cur)\n",
    "        return lines\n",
    "\n",
    "    def block_dims(fnt: ImageFont.FreeTypeFont, lines: list[str]) -> tuple[int, int]:\n",
    "        lh = line_height(fnt)\n",
    "        H = len(lines) * lh\n",
    "        W = 0\n",
    "        for ln in lines:\n",
    "            W = max(W, string_width(ln, fnt))\n",
    "        return W, H\n",
    "\n",
    "    # ---------- fit loop ----------\n",
    "    size = max(min_font, int(font_size))\n",
    "    fnt = ImageFont.truetype(str(font_path), size)\n",
    "    lines = wrap_words(fnt, text, max_w)\n",
    "    W, H = block_dims(fnt, lines)\n",
    "\n",
    "    while (W > max_w or H > max_h) and size > min_font:\n",
    "        size -= 2\n",
    "        fnt = ImageFont.truetype(str(font_path), size)\n",
    "        lines = wrap_words(fnt, text, max_w)\n",
    "        W, H = block_dims(fnt, lines)\n",
    "\n",
    "    # ---------- draw top-left ----------\n",
    "    tx = x + padding_px\n",
    "    ty = y + padding_px\n",
    "    lh = line_height(fnt)\n",
    "\n",
    "    for ln in lines:\n",
    "        cx = tx\n",
    "        for i, ch in enumerate(ln):\n",
    "            draw.text(\n",
    "                (cx, ty),\n",
    "                ch,\n",
    "                font=fnt,\n",
    "                fill=color,\n",
    "                stroke_width=max(0, bold_px),\n",
    "                stroke_fill=color,\n",
    "            )\n",
    "            cw, _ = char_size(ch, fnt)\n",
    "            advance = cw\n",
    "            if i < len(ln) - 1:\n",
    "                nxt = ln[i + 1]\n",
    "                if ch == ' ':\n",
    "                    advance += max(0, space_extra_px)\n",
    "                else:\n",
    "                    if nxt != ' ':\n",
    "                        advance += letter_spacing_px\n",
    "            cx += advance\n",
    "        ty += lh\n",
    "\n",
    "    out_path = out_dir / f\"thumb_black_tl_{_ts()}.png\"\n",
    "    img.save(out_path, \"PNG\", optimize=True)\n",
    "    return str(out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2b6f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: /Users/marcus/Downloads/shorts_thumbnails_storage/thumb_black_tl_20250906_032420.png\n"
     ]
    }
   ],
   "source": [
    "saved_path = render_black_topleft(\n",
    "    image_path=\"/Users/marcus/Downloads/Shorts_thumbv2w.png\",\n",
    "    text=\"Have you ever accidentally saved a life? I like playing clash royale and reaching\",\n",
    "    box=(40, 235, 1200, 200),              # (x, y, w, h) — the white card area\n",
    "    out_dir=\"/Users/marcus/Downloads/shorts_thumbnails_storage\",\n",
    "    font_size=70,                         # target “X size”\n",
    "    min_font=48,\n",
    "    line_spacing=1.42,\n",
    "    letter_spacing_px=0,                   # normal spacing\n",
    "    space_extra_px=4,                     # widen spaces a bit\n",
    "    bold_px=1.55,                             # thickness (0=normal, try 2–4 for bold)\n",
    "    # font_path=None,                      # leave None to auto-find Arial\n",
    ")\n",
    "print(\"Saved to:\", saved_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fdf719",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
